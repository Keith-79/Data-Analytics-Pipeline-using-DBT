[0m04:41:40.130663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaf83d490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffae06ce30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffad772810>]}


============================== 04:41:40.139274 | 9c72453e-cb8e-4186-ae2d-d5900097f7c8 ==============================
[0m04:41:40.139274 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:41:40.140379 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:41:40.144541 [error] [MainThread]: Encountered an error:
Runtime Error
  Could not find profile named 'stock_analysis_project'
[0m04:41:40.145981 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.06278683, "process_in_blocks": "0", "process_kernel_time": 0.133023, "process_mem_max_rss": "98052", "process_out_blocks": "3", "process_user_time": 1.963339}
[0m04:41:40.146553 [debug] [MainThread]: Command `dbt run` failed at 04:41:40.146457 after 0.06 seconds
[0m04:41:40.146967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffadb0a3c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffae154f20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffae156090>]}
[0m04:41:40.147438 [debug] [MainThread]: Flushing usage events
[0m04:41:40.473838 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:44:55.792886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88fa29c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89544740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b1186e0>]}


============================== 04:44:55.802356 | 245e3126-1645-4576-87c0-5e22dbb8121d ==============================
[0m04:44:55.802356 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:44:55.803003 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'send_anonymous_usage_stats': 'True'}
[0m04:44:56.601351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '245e3126-1645-4576-87c0-5e22dbb8121d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88fa3860>]}
[0m04:44:56.652393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '245e3126-1645-4576-87c0-5e22dbb8121d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6c554860>]}
[0m04:44:56.653284 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m04:44:56.817848 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:44:56.819236 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m04:44:56.820303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '245e3126-1645-4576-87c0-5e22dbb8121d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6c9a6db0>]}
[0m04:44:57.998862 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.stock_analysis_project.rsi' (models/example/rsi.sql) depends on a node named 'stock_data' which was not found
[0m04:44:58.000501 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.2664413, "process_in_blocks": "0", "process_kernel_time": 0.302116, "process_mem_max_rss": "205620", "process_out_blocks": "5", "process_user_time": 4.688804}
[0m04:44:58.001271 [debug] [MainThread]: Command `dbt run` failed at 04:44:58.001174 after 2.27 seconds
[0m04:44:58.001636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6c15e030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6d858fb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6cf13860>]}
[0m04:44:58.002093 [debug] [MainThread]: Flushing usage events
[0m04:44:58.333574 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:50:02.274395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0be8170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2e58890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2f18da0>]}


============================== 04:50:02.284922 | c74f27e1-e34d-4a26-b0e3-529f8e841847 ==============================
[0m04:50:02.284922 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:50:02.286111 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:50:03.197361 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c74f27e1-e34d-4a26-b0e3-529f8e841847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84b13260>]}
[0m04:50:03.256016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c74f27e1-e34d-4a26-b0e3-529f8e841847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2937290>]}
[0m04:50:03.257655 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m04:50:03.380015 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:50:03.381469 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m04:50:03.382399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c74f27e1-e34d-4a26-b0e3-529f8e841847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0bea2a0>]}
[0m04:50:04.737970 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.stock_analysis_project.rsi' (models/example/rsi.sql) depends on a node named 'stock_data' which was not found
[0m04:50:04.740169 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.5168934, "process_in_blocks": "0", "process_kernel_time": 0.314393, "process_mem_max_rss": "205796", "process_out_blocks": "5", "process_user_time": 4.790996}
[0m04:50:04.741836 [debug] [MainThread]: Command `dbt run` failed at 04:50:04.741287 after 2.52 seconds
[0m04:50:04.742602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0f898b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa092ba70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7fd8da60>]}
[0m04:50:04.743086 [debug] [MainThread]: Flushing usage events
[0m04:50:05.065952 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:50:40.943471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb58c3f80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5675340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5b3e870>]}


============================== 04:50:40.951951 | fabf4fb0-3ed3-4d0c-8644-e5dc2475b656 ==============================
[0m04:50:40.951951 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:50:40.952922 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:50:41.702531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fabf4fb0-3ed3-4d0c-8644-e5dc2475b656', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5d5bc50>]}
[0m04:50:41.755449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fabf4fb0-3ed3-4d0c-8644-e5dc2475b656', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff98e6f050>]}
[0m04:50:41.756562 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m04:50:41.874265 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:50:41.876479 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m04:50:41.877220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'fabf4fb0-3ed3-4d0c-8644-e5dc2475b656', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9894b5c0>]}
[0m04:50:42.937685 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.stock_analysis_project.rsi' (models/example/rsi.sql) depends on a node named 'stock_data' which was not found
[0m04:50:42.939498 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.0877821, "process_in_blocks": "0", "process_kernel_time": 0.217329, "process_mem_max_rss": "205784", "process_out_blocks": "5", "process_user_time": 4.505841}
[0m04:50:42.940054 [debug] [MainThread]: Command `dbt run` failed at 04:50:42.939956 after 2.09 seconds
[0m04:50:42.940476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb56a7440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff984f06e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff986d3950>]}
[0m04:50:42.940920 [debug] [MainThread]: Flushing usage events
[0m04:50:43.245377 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:54:39.687388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82b68980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82188500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff821acbf0>]}


============================== 04:54:39.696661 | a9184fc7-807a-4b12-97ac-eff6a89a18ec ==============================
[0m04:54:39.696661 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:54:39.697694 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:54:40.562489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a9184fc7-807a-4b12-97ac-eff6a89a18ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff61b15fd0>]}
[0m04:54:40.613851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a9184fc7-807a-4b12-97ac-eff6a89a18ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff61e97b30>]}
[0m04:54:40.614809 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m04:54:40.728943 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:54:40.730361 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m04:54:40.731272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a9184fc7-807a-4b12-97ac-eff6a89a18ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff69318aa0>]}
[0m04:54:42.000501 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m04:54:42.011966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a9184fc7-807a-4b12-97ac-eff6a89a18ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff613b4590>]}
[0m04:54:42.099536 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m04:54:42.102246 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m04:54:42.124207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a9184fc7-807a-4b12-97ac-eff6a89a18ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff615f0710>]}
[0m04:54:42.124744 [info ] [MainThread]: Found 4 models, 4 data tests, 474 macros
[0m04:54:42.125486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9184fc7-807a-4b12-97ac-eff6a89a18ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6157e450>]}
[0m04:54:42.127343 [info ] [MainThread]: 
[0m04:54:42.127900 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m04:54:42.128314 [info ] [MainThread]: 
[0m04:54:42.128963 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m04:54:42.133687 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m04:54:42.178253 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m04:54:42.178938 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m04:54:42.179428 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:54:42.517719 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m04:54:42.518309 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m04:54:42.518793 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
[0m04:54:42.519147 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m04:54:42.519976 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:54:42.520318 [debug] [MainThread]: Connection 'list_USER_DB_BEETLE' was left open.
[0m04:54:42.520809 [debug] [MainThread]: On list_USER_DB_BEETLE: No close available on handle
[0m04:54:42.521120 [info ] [MainThread]: 
[0m04:54:42.521907 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.39 seconds (0.39s).
[0m04:54:42.522630 [error] [MainThread]: Encountered an error:
Runtime Error
  Database error while listing schemas in database "USER_DB_BEETLE"
  Database Error
    250003 (08001): 404 Not Found: post https://xyz12345.us-west-2.snowflakecomputing.com:443/session/v1/login-request?request_id=a98f4768-581e-4b27-b332-d511026a20a3&databaseName=USER_DB_BEETLE&schemaName=analytics&warehouse=BEETLE_QUERY_WH&roleName=SYSADMIN&request_guid=97c9a0eb-54a2-48f2-b2c2-91295020e1ba
[0m04:54:42.524199 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.8839157, "process_in_blocks": "1616", "process_kernel_time": 0.342255, "process_mem_max_rss": "219144", "process_out_blocks": "4573", "process_user_time": 4.991721}
[0m04:54:42.524839 [debug] [MainThread]: Command `dbt run` failed at 04:54:42.524726 after 2.88 seconds
[0m04:54:42.525229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82103590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff619220c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6158a420>]}
[0m04:54:42.525724 [debug] [MainThread]: Flushing usage events
[0m04:54:42.840982 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:59:47.923441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa2e2cc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab8b92b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaa034bf0>]}


============================== 04:59:47.934412 | d39a9bc4-fc29-4036-a4d1-0e67abfdadf3 ==============================
[0m04:59:47.934412 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:59:47.935428 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m04:59:48.676852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd39a9bc4-fc29-4036-a4d1-0e67abfdadf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89710e90>]}
[0m04:59:48.729495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd39a9bc4-fc29-4036-a4d1-0e67abfdadf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b3cc950>]}
[0m04:59:48.730518 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m04:59:48.841723 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:59:48.971053 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:59:48.971520 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:59:48.977713 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m04:59:49.013764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd39a9bc4-fc29-4036-a4d1-0e67abfdadf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff892bbfe0>]}
[0m04:59:49.091096 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m04:59:49.093740 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m04:59:49.117179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd39a9bc4-fc29-4036-a4d1-0e67abfdadf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff892cbc50>]}
[0m04:59:49.117821 [info ] [MainThread]: Found 4 models, 4 data tests, 474 macros
[0m04:59:49.118616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd39a9bc4-fc29-4036-a4d1-0e67abfdadf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9e11a30>]}
[0m04:59:49.120556 [info ] [MainThread]: 
[0m04:59:49.121127 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m04:59:49.121740 [info ] [MainThread]: 
[0m04:59:49.122400 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m04:59:49.127122 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m04:59:49.165351 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m04:59:49.165866 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m04:59:49.166209 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:59:49.387093 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m04:59:49.387666 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m04:59:49.388095 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
[0m04:59:49.388447 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m04:59:49.389293 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:59:49.389614 [debug] [MainThread]: Connection 'list_USER_DB_BEETLE' was left open.
[0m04:59:49.389914 [debug] [MainThread]: On list_USER_DB_BEETLE: No close available on handle
[0m04:59:49.390265 [info ] [MainThread]: 
[0m04:59:49.390988 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.27 seconds (0.27s).
[0m04:59:49.391700 [error] [MainThread]: Encountered an error:
Runtime Error
  Database error while listing schemas in database "USER_DB_BEETLE"
  Database Error
    250003 (08001): 404 Not Found: post https://xyz12345.us-west-2.snowflakecomputing.com:443/session/v1/login-request?request_id=c72ed5a5-ab01-4efc-8231-4197e73fef38&databaseName=USER_DB_BEETLE&schemaName=analytics&warehouse=BEETLE_QUERY_WH&roleName=SYSADMIN&request_guid=728624e0-74b8-4941-b981-e97bb02e81d4
[0m04:59:49.393022 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.5214124, "process_in_blocks": "0", "process_kernel_time": 0.352369, "process_mem_max_rss": "214728", "process_out_blocks": "1008", "process_user_time": 3.745926}
[0m04:59:49.394065 [debug] [MainThread]: Command `dbt run` failed at 04:59:49.393957 after 1.52 seconds
[0m04:59:49.394485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9f298e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8883d0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff892cbda0>]}
[0m04:59:49.394857 [debug] [MainThread]: Flushing usage events
[0m04:59:49.720618 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m05:01:01.040883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1c34c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1c34cb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1c37b00>]}


============================== 05:01:01.049396 | 59c0f69d-eab4-4cf4-a140-74b3e5b08377 ==============================
[0m05:01:01.049396 [info ] [MainThread]: Running with dbt=1.9.4
[0m05:01:01.050104 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m05:01:01.780253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '59c0f69d-eab4-4cf4-a140-74b3e5b08377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa24ba0c0>]}
[0m05:01:01.830449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '59c0f69d-eab4-4cf4-a140-74b3e5b08377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85c96f00>]}
[0m05:01:01.831438 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m05:01:01.947903 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m05:01:02.047960 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m05:01:02.048996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '59c0f69d-eab4-4cf4-a140-74b3e5b08377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1f58950>]}
[0m05:01:03.172579 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m05:01:03.178734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '59c0f69d-eab4-4cf4-a140-74b3e5b08377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8536ee10>]}
[0m05:01:03.252435 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m05:01:03.254494 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m05:01:03.281024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '59c0f69d-eab4-4cf4-a140-74b3e5b08377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84ef6540>]}
[0m05:01:03.281806 [info ] [MainThread]: Found 4 models, 4 data tests, 474 macros
[0m05:01:03.282609 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '59c0f69d-eab4-4cf4-a140-74b3e5b08377', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff850e05c0>]}
[0m05:01:03.284472 [info ] [MainThread]: 
[0m05:01:03.285254 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m05:01:03.285910 [info ] [MainThread]: 
[0m05:01:03.286699 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m05:01:03.291403 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m05:01:03.329375 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m05:01:03.330045 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m05:01:03.330503 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:01:03.617783 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m05:01:03.618357 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m05:01:03.618967 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
[0m05:01:03.619393 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m05:01:03.620246 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:01:03.620546 [debug] [MainThread]: Connection 'list_USER_DB_BEETLE' was left open.
[0m05:01:03.620888 [debug] [MainThread]: On list_USER_DB_BEETLE: No close available on handle
[0m05:01:03.621249 [info ] [MainThread]: 
[0m05:01:03.622011 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.33 seconds (0.33s).
[0m05:01:03.622777 [error] [MainThread]: Encountered an error:
Runtime Error
  Database error while listing schemas in database "USER_DB_BEETLE"
  Database Error
    250001 (08001): Failed to connect to DB: sfedu02-ksb65579.snowflakecomputing.com:443. Role 'SYSADMIN' specified in the connect string is not granted to this user. Contact your local system administrator, or attempt to login with another role, e.g. PUBLIC.
[0m05:01:03.624278 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.6305037, "process_in_blocks": "0", "process_kernel_time": 0.289966, "process_mem_max_rss": "217164", "process_out_blocks": "1981", "process_user_time": 5.055419}
[0m05:01:03.625138 [debug] [MainThread]: Command `dbt run` failed at 05:01:03.625043 after 2.63 seconds
[0m05:01:03.625483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1f5ade0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84f56960>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8534e2a0>]}
[0m05:01:03.625879 [debug] [MainThread]: Flushing usage events
[0m05:01:03.921389 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m05:06:06.514962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2e27440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2e261e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb317cf80>]}


============================== 05:06:06.525163 | 5b5e6f8a-4869-467a-8e31-268324c98ecb ==============================
[0m05:06:06.525163 [info ] [MainThread]: Running with dbt=1.9.4
[0m05:06:06.526157 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m05:06:07.264489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b5e6f8a-4869-467a-8e31-268324c98ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff925d1940>]}
[0m05:06:07.316331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b5e6f8a-4869-467a-8e31-268324c98ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff92e20c20>]}
[0m05:06:07.317320 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m05:06:07.498246 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m05:06:07.598494 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m05:06:07.599451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5b5e6f8a-4869-467a-8e31-268324c98ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2e24bc0>]}
[0m05:06:08.752475 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m05:06:08.758166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b5e6f8a-4869-467a-8e31-268324c98ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91dcd010>]}
[0m05:06:08.870160 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m05:06:08.872354 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m05:06:08.898677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b5e6f8a-4869-467a-8e31-268324c98ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9200af60>]}
[0m05:06:08.901298 [info ] [MainThread]: Found 4 models, 4 data tests, 474 macros
[0m05:06:08.902112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b5e6f8a-4869-467a-8e31-268324c98ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91e13800>]}
[0m05:06:08.905737 [info ] [MainThread]: 
[0m05:06:08.906443 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m05:06:08.907075 [info ] [MainThread]: 
[0m05:06:08.908404 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m05:06:08.916358 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m05:06:08.956697 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m05:06:08.957216 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m05:06:08.957605 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:06:09.369755 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.412 seconds
[0m05:06:09.372916 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE, now list_USER_DB_BEETLE_analytics)
[0m05:06:09.382995 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m05:06:09.383461 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m05:06:09.485049 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 0.101 seconds
[0m05:06:09.488605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b5e6f8a-4869-467a-8e31-268324c98ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2a52de0>]}
[0m05:06:09.495696 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.moving_avg
[0m05:06:09.496405 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics.moving_avg ............................... [RUN]
[0m05:06:09.497302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now model.stock_analysis_project.moving_avg)
[0m05:06:09.497700 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.moving_avg
[0m05:06:09.504243 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.moving_avg"
[0m05:06:09.507007 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.moving_avg
[0m05:06:09.535419 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.moving_avg"
[0m05:06:09.539152 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.moving_avg"
[0m05:06:09.539758 [debug] [Thread-1 (]: On model.stock_analysis_project.moving_avg: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.moving_avg"} */
create or replace   view USER_DB_BEETLE.analytics.moving_avg
  
   as (
    SELECT 
  symbol,
  date,
  close,
  AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS moving_avg_7d
FROM USER_DB_BEETLE.raw.stock_data
  );
[0m05:06:09.761980 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.221 seconds
[0m05:06:09.816616 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5e6f8a-4869-467a-8e31-268324c98ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb4c9f3b0>]}
[0m05:06:09.819665 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics.moving_avg .......................... [[32mSUCCESS 1[0m in 0.32s]
[0m05:06:09.822289 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.moving_avg
[0m05:06:09.823427 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.my_first_dbt_model
[0m05:06:09.824608 [info ] [Thread-1 (]: 2 of 4 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m05:06:09.825845 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.moving_avg, now model.stock_analysis_project.my_first_dbt_model)
[0m05:06:09.827176 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.my_first_dbt_model
[0m05:06:09.834510 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.my_first_dbt_model"
[0m05:06:09.838262 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.my_first_dbt_model
[0m05:06:09.903457 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.my_first_dbt_model"
[0m05:06:09.909736 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.my_first_dbt_model"
[0m05:06:09.912026 [debug] [Thread-1 (]: On model.stock_analysis_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.my_first_dbt_model"} */
create or replace transient table USER_DB_BEETLE.analytics.my_first_dbt_model
         as
        (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
        );
[0m05:06:10.880670 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.967 seconds
[0m05:06:10.884207 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5e6f8a-4869-467a-8e31-268324c98ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9036bef0>]}
[0m05:06:10.884968 [info ] [Thread-1 (]: 2 of 4 OK created sql table model analytics.my_first_dbt_model ................. [[32mSUCCESS 1[0m in 1.06s]
[0m05:06:10.886181 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.my_first_dbt_model
[0m05:06:10.886644 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.rsi
[0m05:06:10.887289 [info ] [Thread-1 (]: 3 of 4 START sql view model analytics.rsi ...................................... [RUN]
[0m05:06:10.888190 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.my_first_dbt_model, now model.stock_analysis_project.rsi)
[0m05:06:10.888541 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.rsi
[0m05:06:10.891151 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.rsi"
[0m05:06:10.892847 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.rsi
[0m05:06:10.896301 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.rsi"
[0m05:06:10.898562 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.rsi"
[0m05:06:10.899036 [debug] [Thread-1 (]: On model.stock_analysis_project.rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.rsi"} */
create or replace   view USER_DB_BEETLE.analytics.rsi
  
   as (
    WITH gains_losses AS (
  SELECT
    symbol,
    date,
    close,
    close - LAG(close) OVER (PARTITION BY symbol ORDER BY date) AS change
  FROM USER_DB_BEETLE.raw.stock_data
),
rsi_calc AS (
  SELECT *,
    CASE WHEN change > 0 THEN change ELSE 0 END AS gain,
    CASE WHEN change < 0 THEN -change ELSE 0 END AS loss
  FROM gains_losses
)
SELECT
  symbol,
  date,
  AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
  AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss,
  100 - (100 / (1 + (AVG(gain) OVER (...) / NULLIF(AVG(loss) OVER (...), 0)))) AS rsi
FROM rsi_calc
  );
[0m05:06:10.992183 [debug] [Thread-1 (]: Snowflake adapter: Snowflake query id: 01bbdfd2-0305-0c98-0004-59ff002ad352
[0m05:06:10.992988 [debug] [Thread-1 (]: Snowflake adapter: Snowflake error: 001003 (42000): SQL compilation error:
syntax error line 23 at position 37 unexpected '.'.
syntax error line 23 at position 67 unexpected '.'.
syntax error line 23 at position 77 unexpected ')'.
[0m05:06:10.997722 [debug] [Thread-1 (]: Database Error in model rsi (models/example/rsi.sql)
  001003 (42000): SQL compilation error:
  syntax error line 23 at position 37 unexpected '.'.
  syntax error line 23 at position 67 unexpected '.'.
  syntax error line 23 at position 77 unexpected ')'.
  compiled code at target/run/stock_analysis_project/models/example/rsi.sql
[0m05:06:10.998565 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5e6f8a-4869-467a-8e31-268324c98ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff903103e0>]}
[0m05:06:10.999377 [error] [Thread-1 (]: 3 of 4 ERROR creating sql view model analytics.rsi ............................. [[31mERROR[0m in 0.11s]
[0m05:06:11.000438 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.rsi
[0m05:06:11.000889 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.my_second_dbt_model
[0m05:06:11.001340 [debug] [Thread-4 (]: Marking all children of 'model.stock_analysis_project.rsi' to be skipped because of status 'error'.  Reason: Database Error in model rsi (models/example/rsi.sql)
  001003 (42000): SQL compilation error:
  syntax error line 23 at position 37 unexpected '.'.
  syntax error line 23 at position 67 unexpected '.'.
  syntax error line 23 at position 77 unexpected ')'.
  compiled code at target/run/stock_analysis_project/models/example/rsi.sql.
[0m05:06:11.001748 [info ] [Thread-1 (]: 4 of 4 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m05:06:11.003487 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.rsi, now model.stock_analysis_project.my_second_dbt_model)
[0m05:06:11.003965 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.my_second_dbt_model
[0m05:06:11.007170 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.my_second_dbt_model"
[0m05:06:11.008649 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.my_second_dbt_model
[0m05:06:11.011247 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.my_second_dbt_model"
[0m05:06:11.012734 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.my_second_dbt_model"
[0m05:06:11.013157 [debug] [Thread-1 (]: On model.stock_analysis_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.my_second_dbt_model"} */
create or replace   view USER_DB_BEETLE.analytics.my_second_dbt_model
  
   as (
    -- Use the `ref` function to select from other models

select *
from USER_DB_BEETLE.analytics.my_first_dbt_model
where id = 1
  );
[0m05:06:11.205068 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.191 seconds
[0m05:06:11.208697 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b5e6f8a-4869-467a-8e31-268324c98ecb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90291c70>]}
[0m05:06:11.209685 [info ] [Thread-1 (]: 4 of 4 OK created sql view model analytics.my_second_dbt_model ................. [[32mSUCCESS 1[0m in 0.21s]
[0m05:06:11.210702 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.my_second_dbt_model
[0m05:06:11.212711 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:06:11.213181 [debug] [MainThread]: Connection 'model.stock_analysis_project.my_second_dbt_model' was left open.
[0m05:06:11.213610 [debug] [MainThread]: On model.stock_analysis_project.my_second_dbt_model: Close
[0m05:06:11.317672 [info ] [MainThread]: 
[0m05:06:11.318630 [info ] [MainThread]: Finished running 1 table model, 3 view models in 0 hours 0 minutes and 2.41 seconds (2.41s).
[0m05:06:11.319854 [debug] [MainThread]: Command end result
[0m05:06:11.351193 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m05:06:11.353304 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m05:06:11.359401 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m05:06:11.359814 [info ] [MainThread]: 
[0m05:06:11.361240 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m05:06:11.361909 [info ] [MainThread]: 
[0m05:06:11.362630 [error] [MainThread]:   Database Error in model rsi (models/example/rsi.sql)
  001003 (42000): SQL compilation error:
  syntax error line 23 at position 37 unexpected '.'.
  syntax error line 23 at position 67 unexpected '.'.
  syntax error line 23 at position 77 unexpected ')'.
  compiled code at target/run/stock_analysis_project/models/example/rsi.sql
[0m05:06:11.362955 [info ] [MainThread]: 
[0m05:06:11.363475 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m05:06:11.364874 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.898392, "process_in_blocks": "24", "process_kernel_time": 0.38444, "process_mem_max_rss": "219540", "process_out_blocks": "2986", "process_user_time": 5.544771}
[0m05:06:11.365353 [debug] [MainThread]: Command `dbt run` failed at 05:06:11.365268 after 4.90 seconds
[0m05:06:11.365742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3556fc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99030e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb33e1010>]}
[0m05:06:11.366117 [debug] [MainThread]: Flushing usage events
[0m05:06:11.770168 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m05:08:37.897227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e4a8500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9dfd8800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e4d5340>]}


============================== 05:08:37.906869 | e530e643-00fc-4604-80e3-61eb5bc7e173 ==============================
[0m05:08:37.906869 [info ] [MainThread]: Running with dbt=1.9.4
[0m05:08:37.907943 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m05:08:38.649382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e530e643-00fc-4604-80e3-61eb5bc7e173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7ddceff0>]}
[0m05:08:38.699827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e530e643-00fc-4604-80e3-61eb5bc7e173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f9a6840>]}
[0m05:08:38.700775 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m05:08:38.813153 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m05:08:38.938970 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m05:08:38.939649 [debug] [MainThread]: Partial parsing: updated file: stock_analysis_project://models/example/rsi.sql
[0m05:08:39.151141 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m05:08:39.158762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e530e643-00fc-4604-80e3-61eb5bc7e173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d3d60c0>]}
[0m05:08:39.237811 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m05:08:39.240011 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m05:08:39.266238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e530e643-00fc-4604-80e3-61eb5bc7e173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d578950>]}
[0m05:08:39.266980 [info ] [MainThread]: Found 4 models, 4 data tests, 474 macros
[0m05:08:39.267697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e530e643-00fc-4604-80e3-61eb5bc7e173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d4d0e60>]}
[0m05:08:39.269505 [info ] [MainThread]: 
[0m05:08:39.270075 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m05:08:39.270566 [info ] [MainThread]: 
[0m05:08:39.271279 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m05:08:39.276119 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m05:08:39.313386 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m05:08:39.313869 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m05:08:39.314224 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:08:39.845216 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.531 seconds
[0m05:08:39.848312 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE, now list_USER_DB_BEETLE_analytics)
[0m05:08:39.858674 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m05:08:39.859149 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m05:08:39.990822 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.131 seconds
[0m05:08:39.995370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e530e643-00fc-4604-80e3-61eb5bc7e173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7dac10a0>]}
[0m05:08:40.000138 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.moving_avg
[0m05:08:40.000786 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics.moving_avg ............................... [RUN]
[0m05:08:40.001796 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now model.stock_analysis_project.moving_avg)
[0m05:08:40.002175 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.moving_avg
[0m05:08:40.008929 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.moving_avg"
[0m05:08:40.011191 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.moving_avg
[0m05:08:40.042918 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.moving_avg"
[0m05:08:40.044813 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.moving_avg"
[0m05:08:40.045213 [debug] [Thread-1 (]: On model.stock_analysis_project.moving_avg: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.moving_avg"} */
create or replace   view USER_DB_BEETLE.analytics.moving_avg
  
   as (
    SELECT 
  symbol,
  date,
  close,
  AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS moving_avg_7d
FROM USER_DB_BEETLE.raw.stock_data
  );
[0m05:08:40.317110 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.271 seconds
[0m05:08:40.357089 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e530e643-00fc-4604-80e3-61eb5bc7e173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0208a40>]}
[0m05:08:40.358921 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics.moving_avg .......................... [[32mSUCCESS 1[0m in 0.35s]
[0m05:08:40.360543 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.moving_avg
[0m05:08:40.363468 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.my_first_dbt_model
[0m05:08:40.364897 [info ] [Thread-1 (]: 2 of 4 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m05:08:40.366192 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.moving_avg, now model.stock_analysis_project.my_first_dbt_model)
[0m05:08:40.367208 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.my_first_dbt_model
[0m05:08:40.374484 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.my_first_dbt_model"
[0m05:08:40.378028 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.my_first_dbt_model
[0m05:08:40.428062 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.my_first_dbt_model"
[0m05:08:40.430997 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.my_first_dbt_model"
[0m05:08:40.431666 [debug] [Thread-1 (]: On model.stock_analysis_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.my_first_dbt_model"} */
create or replace transient table USER_DB_BEETLE.analytics.my_first_dbt_model
         as
        (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
        );
[0m05:08:40.987993 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.555 seconds
[0m05:08:40.991957 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e530e643-00fc-4604-80e3-61eb5bc7e173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d8938f0>]}
[0m05:08:40.992893 [info ] [Thread-1 (]: 2 of 4 OK created sql table model analytics.my_first_dbt_model ................. [[32mSUCCESS 1[0m in 0.63s]
[0m05:08:40.994184 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.my_first_dbt_model
[0m05:08:40.994789 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.rsi
[0m05:08:40.995455 [info ] [Thread-1 (]: 3 of 4 START sql view model analytics.rsi ...................................... [RUN]
[0m05:08:40.996236 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.my_first_dbt_model, now model.stock_analysis_project.rsi)
[0m05:08:40.996696 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.rsi
[0m05:08:40.999186 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.rsi"
[0m05:08:41.000632 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.rsi
[0m05:08:41.003717 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.rsi"
[0m05:08:41.005893 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.rsi"
[0m05:08:41.006344 [debug] [Thread-1 (]: On model.stock_analysis_project.rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.rsi"} */
create or replace   view USER_DB_BEETLE.analytics.rsi
  
   as (
    WITH gains_losses AS (
  SELECT
    symbol,
    date,
    close,
    close - LAG(close) OVER (PARTITION BY symbol ORDER BY date) AS change
  FROM USER_DB_BEETLE.raw.stock_data
),
rsi_calc AS (
  SELECT *,
    CASE WHEN change > 0 THEN change ELSE 0 END AS gain,
    CASE WHEN change < 0 THEN -change ELSE 0 END AS loss
  FROM gains_losses
)
SELECT
  symbol,
  date,
  AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
  AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss,
  100 - (
    100 / (
      1 + (
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW)
        /
        NULLIF(AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW), 0)
      )
    )
  ) AS rsi
FROM rsi_calc
  );
[0m05:08:41.287253 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.280 seconds
[0m05:08:41.290960 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e530e643-00fc-4604-80e3-61eb5bc7e173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5dc23bc0>]}
[0m05:08:41.291941 [info ] [Thread-1 (]: 3 of 4 OK created sql view model analytics.rsi ................................. [[32mSUCCESS 1[0m in 0.29s]
[0m05:08:41.293147 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.rsi
[0m05:08:41.293715 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.my_second_dbt_model
[0m05:08:41.294285 [info ] [Thread-1 (]: 4 of 4 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m05:08:41.294968 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.rsi, now model.stock_analysis_project.my_second_dbt_model)
[0m05:08:41.295428 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.my_second_dbt_model
[0m05:08:41.298842 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.my_second_dbt_model"
[0m05:08:41.300275 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.my_second_dbt_model
[0m05:08:41.303106 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.my_second_dbt_model"
[0m05:08:41.304713 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.my_second_dbt_model"
[0m05:08:41.305132 [debug] [Thread-1 (]: On model.stock_analysis_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.my_second_dbt_model"} */
create or replace   view USER_DB_BEETLE.analytics.my_second_dbt_model
  
   as (
    -- Use the `ref` function to select from other models

select *
from USER_DB_BEETLE.analytics.my_first_dbt_model
where id = 1
  );
[0m05:08:41.499687 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.194 seconds
[0m05:08:41.502856 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e530e643-00fc-4604-80e3-61eb5bc7e173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5dbff4d0>]}
[0m05:08:41.503507 [info ] [Thread-1 (]: 4 of 4 OK created sql view model analytics.my_second_dbt_model ................. [[32mSUCCESS 1[0m in 0.21s]
[0m05:08:41.504536 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.my_second_dbt_model
[0m05:08:41.505878 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:08:41.506218 [debug] [MainThread]: Connection 'model.stock_analysis_project.my_second_dbt_model' was left open.
[0m05:08:41.506538 [debug] [MainThread]: On model.stock_analysis_project.my_second_dbt_model: Close
[0m05:08:41.584933 [info ] [MainThread]: 
[0m05:08:41.585638 [info ] [MainThread]: Finished running 1 table model, 3 view models in 0 hours 0 minutes and 2.31 seconds (2.31s).
[0m05:08:41.587009 [debug] [MainThread]: Command end result
[0m05:08:41.685605 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m05:08:41.687768 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m05:08:41.694899 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m05:08:41.695231 [info ] [MainThread]: 
[0m05:08:41.696027 [info ] [MainThread]: [32mCompleted successfully[0m
[0m05:08:41.696373 [info ] [MainThread]: 
[0m05:08:41.696720 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m05:08:41.697950 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.850829, "process_in_blocks": "0", "process_kernel_time": 0.360535, "process_mem_max_rss": "218256", "process_out_blocks": "2990", "process_user_time": 4.600594}
[0m05:08:41.698439 [debug] [MainThread]: Command `dbt run` succeeded at 05:08:41.698341 after 3.85 seconds
[0m05:08:41.698867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e4a8500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa074fd70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e30f920>]}
[0m05:08:41.699444 [debug] [MainThread]: Flushing usage events
[0m05:08:42.097387 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m06:02:40.565447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82694e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82695e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82696d50>]}


============================== 06:02:40.575351 | 19f83f41-f7b1-4613-872b-bf3f73378cda ==============================
[0m06:02:40.575351 [info ] [MainThread]: Running with dbt=1.9.4
[0m06:02:40.576510 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m06:02:41.396328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '19f83f41-f7b1-4613-872b-bf3f73378cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8236ca10>]}
[0m06:02:41.446506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '19f83f41-f7b1-4613-872b-bf3f73378cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff61bc0800>]}
[0m06:02:41.447481 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m06:02:41.575989 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m06:02:41.851092 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:02:41.852056 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:02:41.864005 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m06:02:41.924338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '19f83f41-f7b1-4613-872b-bf3f73378cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff61acfaa0>]}
[0m06:02:42.023501 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m06:02:42.026626 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m06:02:42.049974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '19f83f41-f7b1-4613-872b-bf3f73378cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6178be00>]}
[0m06:02:42.050568 [info ] [MainThread]: Found 4 models, 4 data tests, 474 macros
[0m06:02:42.051465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '19f83f41-f7b1-4613-872b-bf3f73378cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff61acc290>]}
[0m06:02:42.053345 [info ] [MainThread]: 
[0m06:02:42.054033 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m06:02:42.054532 [info ] [MainThread]: 
[0m06:02:42.055242 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m06:02:42.060664 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m06:02:42.103260 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m06:02:42.103863 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m06:02:42.104211 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:02:42.810691 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.706 seconds
[0m06:02:42.814983 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE, now list_USER_DB_BEETLE_analytics)
[0m06:02:42.829920 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m06:02:42.831395 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m06:02:42.990668 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.159 seconds
[0m06:02:42.996088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '19f83f41-f7b1-4613-872b-bf3f73378cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff83f10b60>]}
[0m06:02:43.000794 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.moving_avg
[0m06:02:43.001504 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics.moving_avg ............................... [RUN]
[0m06:02:43.002426 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now model.stock_analysis_project.moving_avg)
[0m06:02:43.002807 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.moving_avg
[0m06:02:43.010738 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.moving_avg"
[0m06:02:43.012731 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.moving_avg
[0m06:02:43.041397 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.moving_avg"
[0m06:02:43.043050 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.moving_avg"
[0m06:02:43.043428 [debug] [Thread-1 (]: On model.stock_analysis_project.moving_avg: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.moving_avg"} */
create or replace   view USER_DB_BEETLE.analytics.moving_avg
  
   as (
    SELECT 
  symbol,
  date,
  close,
  AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS moving_avg_7d
FROM USER_DB_BEETLE.raw.stock_data
  );
[0m06:02:43.324889 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.281 seconds
[0m06:02:43.352074 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19f83f41-f7b1-4613-872b-bf3f73378cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8448f3e0>]}
[0m06:02:43.352948 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics.moving_avg .......................... [[32mSUCCESS 1[0m in 0.35s]
[0m06:02:43.354012 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.moving_avg
[0m06:02:43.354550 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.my_first_dbt_model
[0m06:02:43.355110 [info ] [Thread-1 (]: 2 of 4 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m06:02:43.355732 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.moving_avg, now model.stock_analysis_project.my_first_dbt_model)
[0m06:02:43.356134 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.my_first_dbt_model
[0m06:02:43.358800 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.my_first_dbt_model"
[0m06:02:43.360511 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.my_first_dbt_model
[0m06:02:43.383319 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.my_first_dbt_model"
[0m06:02:43.384946 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.my_first_dbt_model"
[0m06:02:43.385347 [debug] [Thread-1 (]: On model.stock_analysis_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.my_first_dbt_model"} */
create or replace transient table USER_DB_BEETLE.analytics.my_first_dbt_model
         as
        (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
        );
[0m06:02:44.605544 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1.220 seconds
[0m06:02:44.609642 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19f83f41-f7b1-4613-872b-bf3f73378cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff60aadd30>]}
[0m06:02:44.610764 [info ] [Thread-1 (]: 2 of 4 OK created sql table model analytics.my_first_dbt_model ................. [[32mSUCCESS 1[0m in 1.25s]
[0m06:02:44.612095 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.my_first_dbt_model
[0m06:02:44.612769 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.rsi
[0m06:02:44.613414 [info ] [Thread-1 (]: 3 of 4 START sql view model analytics.rsi ...................................... [RUN]
[0m06:02:44.614230 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.my_first_dbt_model, now model.stock_analysis_project.rsi)
[0m06:02:44.614678 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.rsi
[0m06:02:44.617126 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.rsi"
[0m06:02:44.618371 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.rsi
[0m06:02:44.621346 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.rsi"
[0m06:02:44.623402 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.rsi"
[0m06:02:44.623877 [debug] [Thread-1 (]: On model.stock_analysis_project.rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.rsi"} */
create or replace   view USER_DB_BEETLE.analytics.rsi
  
   as (
    WITH gains_losses AS (
  SELECT
    symbol,
    date,
    close,
    close - LAG(close) OVER (PARTITION BY symbol ORDER BY date) AS change
  FROM USER_DB_BEETLE.raw.stock_data
),
rsi_calc AS (
  SELECT *,
    CASE WHEN change > 0 THEN change ELSE 0 END AS gain,
    CASE WHEN change < 0 THEN -change ELSE 0 END AS loss
  FROM gains_losses
)
SELECT
  symbol,
  date,
  AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
  AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss,
  100 - (
    100 / (
      1 + (
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW)
        /
        NULLIF(AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW), 0)
      )
    )
  ) AS rsi
FROM rsi_calc
  );
[0m06:02:44.943057 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.318 seconds
[0m06:02:44.945559 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19f83f41-f7b1-4613-872b-bf3f73378cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff60add970>]}
[0m06:02:44.946384 [info ] [Thread-1 (]: 3 of 4 OK created sql view model analytics.rsi ................................. [[32mSUCCESS 1[0m in 0.33s]
[0m06:02:44.947229 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.rsi
[0m06:02:44.947687 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.my_second_dbt_model
[0m06:02:44.948177 [info ] [Thread-1 (]: 4 of 4 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m06:02:44.948870 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.rsi, now model.stock_analysis_project.my_second_dbt_model)
[0m06:02:44.949288 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.my_second_dbt_model
[0m06:02:44.952120 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.my_second_dbt_model"
[0m06:02:44.953191 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.my_second_dbt_model
[0m06:02:44.955898 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.my_second_dbt_model"
[0m06:02:44.957036 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.my_second_dbt_model"
[0m06:02:44.957438 [debug] [Thread-1 (]: On model.stock_analysis_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.my_second_dbt_model"} */
create or replace   view USER_DB_BEETLE.analytics.my_second_dbt_model
  
   as (
    -- Use the `ref` function to select from other models

select *
from USER_DB_BEETLE.analytics.my_first_dbt_model
where id = 1
  );
[0m06:02:45.218900 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.261 seconds
[0m06:02:45.221424 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19f83f41-f7b1-4613-872b-bf3f73378cda', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff60132de0>]}
[0m06:02:45.222104 [info ] [Thread-1 (]: 4 of 4 OK created sql view model analytics.my_second_dbt_model ................. [[32mSUCCESS 1[0m in 0.27s]
[0m06:02:45.223077 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.my_second_dbt_model
[0m06:02:45.224502 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:02:45.224834 [debug] [MainThread]: Connection 'model.stock_analysis_project.my_second_dbt_model' was left open.
[0m06:02:45.225145 [debug] [MainThread]: On model.stock_analysis_project.my_second_dbt_model: Close
[0m06:02:45.311352 [info ] [MainThread]: 
[0m06:02:45.312350 [info ] [MainThread]: Finished running 1 table model, 3 view models in 0 hours 0 minutes and 3.26 seconds (3.26s).
[0m06:02:45.313748 [debug] [MainThread]: Command end result
[0m06:02:45.359287 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m06:02:45.362070 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m06:02:45.375098 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m06:02:45.375839 [info ] [MainThread]: 
[0m06:02:45.376931 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:02:45.377544 [info ] [MainThread]: 
[0m06:02:45.378063 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m06:02:45.379243 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.8635473, "process_in_blocks": "0", "process_kernel_time": 0.403907, "process_mem_max_rss": "215220", "process_out_blocks": "2014", "process_user_time": 4.345275}
[0m06:02:45.379933 [debug] [MainThread]: Command `dbt run` succeeded at 06:02:45.379792 after 4.86 seconds
[0m06:02:45.380575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82373770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff61be7ce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff60126870>]}
[0m06:02:45.381149 [debug] [MainThread]: Flushing usage events
[0m06:02:45.786564 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:24:48.723349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7ae39b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7396e70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7a09a60>]}


============================== 19:24:48.730842 | 2f4dfef0-ed52-49f6-aff4-6a08c28e21c0 ==============================
[0m19:24:48.730842 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:24:48.731786 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:24:49.526672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2f4dfef0-ed52-49f6-aff4-6a08c28e21c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff96b59700>]}
[0m19:24:49.576207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2f4dfef0-ed52-49f6-aff4-6a08c28e21c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb97c9c40>]}
[0m19:24:49.577890 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:24:49.762964 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:24:49.903940 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 4 files added, 0 files changed.
[0m19:24:49.904772 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://tests/not_null_stock_metrics.yml
[0m19:24:49.905169 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://models/example/raw_stock_data.sql
[0m19:24:49.905512 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://models/example/stock_metrics.sql
[0m19:24:49.905884 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://snapshots/stock_snapshot.sql
[0m19:24:50.359236 [error] [MainThread]: Encountered an error:
Compilation Error
  Snapshot 'snapshot.stock_analysis_project.stock_snapshot' (snapshots/stock_snapshot.sql) depends on a node named 'rawstock_data' which was not found
[0m19:24:50.361176 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.685731, "process_in_blocks": "464", "process_kernel_time": 0.290699, "process_mem_max_rss": "212424", "process_out_blocks": "5", "process_user_time": 3.949256}
[0m19:24:50.361672 [debug] [MainThread]: Command `dbt run` failed at 19:24:50.361556 after 1.69 seconds
[0m19:24:50.362118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7324f80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9546a060>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff954c4dd0>]}
[0m19:24:50.362522 [debug] [MainThread]: Flushing usage events
[0m19:24:50.687402 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:31:05.839002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb956b350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbbf17c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb956a1b0>]}


============================== 19:31:05.846923 | 31a91c45-4c20-45b8-a5df-a43867304e91 ==============================
[0m19:31:05.846923 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:31:05.847820 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'config', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir config', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:31:05.852282 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'DBT_ACCOUNT'
[0m19:31:05.853614 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.062240418, "process_in_blocks": "0", "process_kernel_time": 0.135994, "process_mem_max_rss": "100036", "process_out_blocks": "2", "process_user_time": 1.937922}
[0m19:31:05.854138 [debug] [MainThread]: Command `dbt run` failed at 19:31:05.854028 after 0.06 seconds
[0m19:31:05.854535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8fedee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb95694f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb956a1b0>]}
[0m19:31:05.854992 [debug] [MainThread]: Flushing usage events
[0m19:31:06.151668 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:37:02.799078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ab23a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8b1f3380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e9b53d0>]}


============================== 19:37:02.806644 | 697ce894-cef9-49c5-9148-38df454c6ea5 ==============================
[0m19:37:02.806644 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:37:02.807353 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:37:03.561850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '697ce894-cef9-49c5-9148-38df454c6ea5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6a39f0b0>]}
[0m19:37:03.612807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '697ce894-cef9-49c5-9148-38df454c6ea5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6a50c9b0>]}
[0m19:37:03.613934 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:37:03.729293 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:37:03.860583 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 4 files added, 0 files changed.
[0m19:37:03.861467 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://tests/not_null_stock_metrics.yml
[0m19:37:03.861897 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://models/example/stock_metrics.sql
[0m19:37:03.862287 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://models/example/raw_stock_data.sql
[0m19:37:03.862711 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://snapshots/stock_snapshot.sql
[0m19:37:04.351908 [error] [MainThread]: Encountered an error:
Compilation Error
  Snapshot 'snapshot.stock_analysis_project.stock_snapshot' (snapshots/stock_snapshot.sql) depends on a node named 'rawstock_data' which was not found
[0m19:37:04.354282 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6144369, "process_in_blocks": "0", "process_kernel_time": 0.29255, "process_mem_max_rss": "212368", "process_out_blocks": "5", "process_user_time": 4.051319}
[0m19:37:04.354747 [debug] [MainThread]: Command `dbt run` failed at 19:37:04.354658 after 1.62 seconds
[0m19:37:04.355167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8afdc140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff68ad7950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6a1547a0>]}
[0m19:37:04.355589 [debug] [MainThread]: Flushing usage events
[0m19:37:04.672213 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:39:04.872654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89be9b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89d8b350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ba7e5a0>]}


============================== 19:39:04.879830 | e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf ==============================
[0m19:39:04.879830 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:39:04.880585 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:39:05.603677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6d41b230>]}
[0m19:39:05.650230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6d38fa10>]}
[0m19:39:05.651056 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:39:05.763222 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:39:05.892567 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 4 files added, 0 files changed.
[0m19:39:05.893250 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://tests/not_null_stock_metrics.yml
[0m19:39:05.893647 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://models/example/raw_stock_data.sql
[0m19:39:05.894011 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://snapshots/stock_snapshot.sql
[0m19:39:05.894333 [debug] [MainThread]: Partial parsing: added file: stock_analysis_project://models/example/stock_metrics.sql
[0m19:39:06.399257 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m19:39:06.405387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6cdc47a0>]}
[0m19:39:06.490647 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:39:06.492602 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:39:06.596596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff53a1d760>]}
[0m19:39:06.597114 [info ] [MainThread]: Found 6 models, 6 data tests, 1 snapshot, 474 macros
[0m19:39:06.597906 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6ced0290>]}
[0m19:39:06.599867 [info ] [MainThread]: 
[0m19:39:06.600487 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:39:06.601028 [info ] [MainThread]: 
[0m19:39:06.601743 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:39:06.606752 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m19:39:06.642328 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m19:39:06.642899 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m19:39:06.643322 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:39:07.071888 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.428 seconds
[0m19:39:07.075060 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE, now list_USER_DB_BEETLE_analytics)
[0m19:39:07.085085 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m19:39:07.085475 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m19:39:07.206817 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 0.121 seconds
[0m19:39:07.210273 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now list_USER_DB_BEETLE_snapshots)
[0m19:39:07.215296 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_snapshots"
[0m19:39:07.215887 [debug] [ThreadPool]: On list_USER_DB_BEETLE_snapshots: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_snapshots"} */
show objects in USER_DB_BEETLE.snapshots limit 10000;
[0m19:39:07.314523 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01bbe33b-0305-0c96-0004-59ff002bfff6
[0m19:39:07.315189 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m19:39:07.315765 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m19:39:07.316106 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m19:39:07.316915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ba43110>]}
[0m19:39:07.322778 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.moving_avg
[0m19:39:07.323464 [info ] [Thread-1 (]: 1 of 6 START sql view model analytics.moving_avg ............................... [RUN]
[0m19:39:07.324340 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_snapshots, now model.stock_analysis_project.moving_avg)
[0m19:39:07.324721 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.moving_avg
[0m19:39:07.332397 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.moving_avg"
[0m19:39:07.333629 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.moving_avg
[0m19:39:07.360980 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.moving_avg"
[0m19:39:07.362342 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.moving_avg"
[0m19:39:07.362722 [debug] [Thread-1 (]: On model.stock_analysis_project.moving_avg: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.moving_avg"} */
create or replace   view USER_DB_BEETLE.analytics.moving_avg
  
   as (
    SELECT 
  symbol,
  date,
  close,
  AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS moving_avg_7d
FROM USER_DB_BEETLE.raw.stock_data
  );
[0m19:39:07.616874 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.254 seconds
[0m19:39:07.650151 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8c005760>]}
[0m19:39:07.650965 [info ] [Thread-1 (]: 1 of 6 OK created sql view model analytics.moving_avg .......................... [[32mSUCCESS 1[0m in 0.32s]
[0m19:39:07.652078 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.moving_avg
[0m19:39:07.653149 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.my_first_dbt_model
[0m19:39:07.654530 [info ] [Thread-1 (]: 2 of 6 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m19:39:07.655308 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.moving_avg, now model.stock_analysis_project.my_first_dbt_model)
[0m19:39:07.655667 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.my_first_dbt_model
[0m19:39:07.658432 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.my_first_dbt_model"
[0m19:39:07.659428 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.my_first_dbt_model
[0m19:39:07.683554 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.my_first_dbt_model"
[0m19:39:07.685058 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.my_first_dbt_model"
[0m19:39:07.685503 [debug] [Thread-1 (]: On model.stock_analysis_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.my_first_dbt_model"} */
create or replace transient table USER_DB_BEETLE.analytics.my_first_dbt_model
         as
        (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
        );
[0m19:39:08.756811 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 1.071 seconds
[0m19:39:08.760408 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff52e93d70>]}
[0m19:39:08.761295 [info ] [Thread-1 (]: 2 of 6 OK created sql table model analytics.my_first_dbt_model ................. [[32mSUCCESS 1[0m in 1.11s]
[0m19:39:08.762639 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.my_first_dbt_model
[0m19:39:08.763268 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.raw_stock_data
[0m19:39:08.763984 [info ] [Thread-1 (]: 3 of 6 START sql view model analytics.raw_stock_data ........................... [RUN]
[0m19:39:08.764634 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.my_first_dbt_model, now model.stock_analysis_project.raw_stock_data)
[0m19:39:08.765046 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.raw_stock_data
[0m19:39:08.767468 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.raw_stock_data"
[0m19:39:08.768839 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.raw_stock_data
[0m19:39:08.771727 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.raw_stock_data"
[0m19:39:08.773110 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.raw_stock_data"
[0m19:39:08.773557 [debug] [Thread-1 (]: On model.stock_analysis_project.raw_stock_data: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.raw_stock_data"} */
create or replace   view USER_DB_BEETLE.analytics.raw_stock_data
  
   as (
    -- models/raw_stock_data.sql
select * from raw.stock_data
  );
[0m19:39:08.973502 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.199 seconds
[0m19:39:08.977070 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff52e93650>]}
[0m19:39:08.978167 [info ] [Thread-1 (]: 3 of 6 OK created sql view model analytics.raw_stock_data ...................... [[32mSUCCESS 1[0m in 0.21s]
[0m19:39:08.979563 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.raw_stock_data
[0m19:39:08.980258 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.rsi
[0m19:39:08.980994 [info ] [Thread-1 (]: 4 of 6 START sql view model analytics.rsi ...................................... [RUN]
[0m19:39:08.981797 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.raw_stock_data, now model.stock_analysis_project.rsi)
[0m19:39:08.982236 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.rsi
[0m19:39:08.984738 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.rsi"
[0m19:39:08.986014 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.rsi
[0m19:39:08.988881 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.rsi"
[0m19:39:08.990824 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.rsi"
[0m19:39:08.991218 [debug] [Thread-1 (]: On model.stock_analysis_project.rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.rsi"} */
create or replace   view USER_DB_BEETLE.analytics.rsi
  
   as (
    WITH gains_losses AS (
  SELECT
    symbol,
    date,
    close,
    close - LAG(close) OVER (PARTITION BY symbol ORDER BY date) AS change
  FROM USER_DB_BEETLE.raw.stock_data
),
rsi_calc AS (
  SELECT *,
    CASE WHEN change > 0 THEN change ELSE 0 END AS gain,
    CASE WHEN change < 0 THEN -change ELSE 0 END AS loss
  FROM gains_losses
)
SELECT
  symbol,
  date,
  AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
  AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss,
  100 - (
    100 / (
      1 + (
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW)
        /
        NULLIF(AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW), 0)
      )
    )
  ) AS rsi
FROM rsi_calc
  );
[0m19:39:09.247146 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.255 seconds
[0m19:39:09.249873 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff513b3e90>]}
[0m19:39:09.250488 [info ] [Thread-1 (]: 4 of 6 OK created sql view model analytics.rsi ................................. [[32mSUCCESS 1[0m in 0.27s]
[0m19:39:09.251516 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.rsi
[0m19:39:09.251926 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.my_second_dbt_model
[0m19:39:09.252587 [info ] [Thread-1 (]: 5 of 6 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m19:39:09.253282 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.rsi, now model.stock_analysis_project.my_second_dbt_model)
[0m19:39:09.253657 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.my_second_dbt_model
[0m19:39:09.257653 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.my_second_dbt_model"
[0m19:39:09.258611 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.my_second_dbt_model
[0m19:39:09.260964 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.my_second_dbt_model"
[0m19:39:09.262263 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.my_second_dbt_model"
[0m19:39:09.262729 [debug] [Thread-1 (]: On model.stock_analysis_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.my_second_dbt_model"} */
create or replace   view USER_DB_BEETLE.analytics.my_second_dbt_model
  
   as (
    -- Use the `ref` function to select from other models

select *
from USER_DB_BEETLE.analytics.my_first_dbt_model
where id = 1
  );
[0m19:39:09.437009 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.174 seconds
[0m19:39:09.440467 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff52db3b90>]}
[0m19:39:09.441323 [info ] [Thread-1 (]: 5 of 6 OK created sql view model analytics.my_second_dbt_model ................. [[32mSUCCESS 1[0m in 0.19s]
[0m19:39:09.442400 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.my_second_dbt_model
[0m19:39:09.442891 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.stock_metrics
[0m19:39:09.443462 [info ] [Thread-1 (]: 6 of 6 START sql view model analytics.stock_metrics ............................ [RUN]
[0m19:39:09.444345 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.my_second_dbt_model, now model.stock_analysis_project.stock_metrics)
[0m19:39:09.444784 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.stock_metrics
[0m19:39:09.448187 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.stock_metrics"
[0m19:39:09.449634 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.stock_metrics
[0m19:39:09.452841 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.stock_metrics"
[0m19:39:09.454812 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.stock_metrics"
[0m19:39:09.455219 [debug] [Thread-1 (]: On model.stock_analysis_project.stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.stock_metrics"} */
create or replace   view USER_DB_BEETLE.analytics.stock_metrics
  
   as (
    -- models/stock_metrics.sql
with raw_data as (
  select *, row_number() over (partition by symbol order by date) as row_num
  from USER_DB_BEETLE.analytics.raw_stock_data
),

calc as (
  select 
    symbol,
    date,
    close,
    avg(close) over (partition by symbol order by date rows between 13 preceding and current row) as ma14,
    avg(close) over (partition by symbol order by date rows between 49 preceding and current row) as ma50
  from raw_data
)

select * from calc
  );
[0m19:39:09.727410 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.272 seconds
[0m19:39:09.730194 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e386b5f8-2c3e-4a4b-9ef7-d0edc34e7faf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff52db1ee0>]}
[0m19:39:09.730893 [info ] [Thread-1 (]: 6 of 6 OK created sql view model analytics.stock_metrics ....................... [[32mSUCCESS 1[0m in 0.29s]
[0m19:39:09.732530 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.stock_metrics
[0m19:39:09.734592 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:39:09.735065 [debug] [MainThread]: Connection 'model.stock_analysis_project.stock_metrics' was left open.
[0m19:39:09.735452 [debug] [MainThread]: On model.stock_analysis_project.stock_metrics: Close
[0m19:39:09.815561 [info ] [MainThread]: 
[0m19:39:09.816329 [info ] [MainThread]: Finished running 1 table model, 5 view models in 0 hours 0 minutes and 3.21 seconds (3.21s).
[0m19:39:09.818308 [debug] [MainThread]: Command end result
[0m19:39:09.850248 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:39:09.852455 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:39:09.858640 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m19:39:09.859403 [info ] [MainThread]: 
[0m19:39:09.860301 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:39:09.861107 [info ] [MainThread]: 
[0m19:39:09.861946 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m19:39:09.863145 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.036805, "process_in_blocks": "312", "process_kernel_time": 0.32494, "process_mem_max_rss": "224584", "process_out_blocks": "3085", "process_user_time": 4.502172}
[0m19:39:09.863529 [debug] [MainThread]: Command `dbt run` succeeded at 19:39:09.863444 after 5.04 seconds
[0m19:39:09.863907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8966dc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89a77b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff52e549e0>]}
[0m19:39:09.864244 [debug] [MainThread]: Flushing usage events
[0m19:39:10.251792 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:39:12.785011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab4bfb00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab4bfb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab4bfce0>]}


============================== 19:39:12.793166 | f8aa3965-0fcd-400d-b5ea-eb077af54faa ==============================
[0m19:39:12.793166 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:39:12.794084 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:39:13.557904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f8aa3965-0fcd-400d-b5ea-eb077af54faa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9117aa20>]}
[0m19:39:13.610303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f8aa3965-0fcd-400d-b5ea-eb077af54faa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaaf5e060>]}
[0m19:39:13.611315 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:39:13.733275 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:39:13.877066 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:39:13.877610 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:39:13.883441 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m19:39:13.926520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f8aa3965-0fcd-400d-b5ea-eb077af54faa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a37de80>]}
[0m19:39:14.009026 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:39:14.010969 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:39:14.042689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f8aa3965-0fcd-400d-b5ea-eb077af54faa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89e6e900>]}
[0m19:39:14.043216 [info ] [MainThread]: Found 6 models, 6 data tests, 1 snapshot, 474 macros
[0m19:39:14.043663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f8aa3965-0fcd-400d-b5ea-eb077af54faa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89ed5f10>]}
[0m19:39:14.046528 [info ] [MainThread]: 
[0m19:39:14.047244 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:39:14.047827 [info ] [MainThread]: 
[0m19:39:14.048548 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:39:14.053660 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE_snapshots'
[0m19:39:14.092028 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_snapshots"
[0m19:39:14.092566 [debug] [ThreadPool]: On list_USER_DB_BEETLE_snapshots: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_snapshots"} */
show objects in USER_DB_BEETLE.snapshots limit 10000;
[0m19:39:14.092928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:39:14.478361 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01bbe33b-0305-0c96-0004-59ff002bfffe
[0m19:39:14.479079 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m19:39:14.479591 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m19:39:14.479942 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m19:39:14.480635 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_snapshots, now list_USER_DB_BEETLE_analytics)
[0m19:39:14.483041 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m19:39:14.483409 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m19:39:14.594445 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.111 seconds
[0m19:39:14.600068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f8aa3965-0fcd-400d-b5ea-eb077af54faa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a71afc0>]}
[0m19:39:14.604744 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:39:14.607304 [info ] [Thread-1 (]: 1 of 6 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m19:39:14.608267 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710)
[0m19:39:14.608897 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:39:14.624623 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m19:39:14.626556 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:39:14.646363 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m19:39:14.648156 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m19:39:14.648594 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from USER_DB_BEETLE.analytics.my_first_dbt_model
where id is null



      
    ) dbt_internal_test
[0m19:39:15.022334 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.373 seconds
[0m19:39:15.034592 [error] [Thread-1 (]: 1 of 6 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.43s]
[0m19:39:15.035648 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:39:15.036242 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778
[0m19:39:15.036778 [info ] [Thread-1 (]: 2 of 6 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m19:39:15.037542 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710, now test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778)
[0m19:39:15.037904 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778
[0m19:39:15.041934 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778"
[0m19:39:15.043162 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778
[0m19:39:15.045552 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778"
[0m19:39:15.046925 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778"
[0m19:39:15.047303 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from USER_DB_BEETLE.analytics.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
[0m19:39:15.454129 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.406 seconds
[0m19:39:15.457795 [info ] [Thread-1 (]: 2 of 6 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 0.42s]
[0m19:39:15.459101 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778
[0m19:39:15.459632 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:39:15.460151 [info ] [Thread-1 (]: 3 of 6 START test not_null_stock_metrics_close ................................. [RUN]
[0m19:39:15.461001 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778, now test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c)
[0m19:39:15.461508 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:39:15.466626 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:39:15.468652 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:39:15.471280 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:39:15.473646 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:39:15.474039 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select close
from USER_DB_BEETLE.analytics.stock_metrics
where close is null



      
    ) dbt_internal_test
[0m19:39:15.877955 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.403 seconds
[0m19:39:15.881264 [info ] [Thread-1 (]: 3 of 6 PASS not_null_stock_metrics_close ....................................... [[32mPASS[0m in 0.42s]
[0m19:39:15.882547 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:39:15.883105 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:39:15.883605 [info ] [Thread-1 (]: 4 of 6 START test not_null_stock_metrics_symbol ................................ [RUN]
[0m19:39:15.884464 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c, now test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7)
[0m19:39:15.884925 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:39:15.890253 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:39:15.891754 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:39:15.894740 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:39:15.896443 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:39:15.896818 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from USER_DB_BEETLE.analytics.stock_metrics
where symbol is null



      
    ) dbt_internal_test
[0m19:39:16.266563 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.369 seconds
[0m19:39:16.269830 [info ] [Thread-1 (]: 4 of 6 PASS not_null_stock_metrics_symbol ...................................... [[32mPASS[0m in 0.39s]
[0m19:39:16.271103 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:39:16.271592 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321
[0m19:39:16.272219 [info ] [Thread-1 (]: 5 of 6 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m19:39:16.273506 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7, now test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321)
[0m19:39:16.274154 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321
[0m19:39:16.281699 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321"
[0m19:39:16.282960 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321
[0m19:39:16.286820 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321"
[0m19:39:16.288209 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321"
[0m19:39:16.288621 [debug] [Thread-1 (]: On test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from USER_DB_BEETLE.analytics.my_first_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:39:16.469730 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.180 seconds
[0m19:39:16.473077 [info ] [Thread-1 (]: 5 of 6 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.20s]
[0m19:39:16.474423 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321
[0m19:39:16.474960 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493
[0m19:39:16.475459 [info ] [Thread-1 (]: 6 of 6 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m19:39:16.476305 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321, now test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493)
[0m19:39:16.476726 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493
[0m19:39:16.481572 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m19:39:16.482957 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493
[0m19:39:16.485503 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m19:39:16.486998 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m19:39:16.487363 [debug] [Thread-1 (]: On test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from USER_DB_BEETLE.analytics.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:39:16.621636 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.134 seconds
[0m19:39:16.623933 [info ] [Thread-1 (]: 6 of 6 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 0.15s]
[0m19:39:16.624984 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493
[0m19:39:16.626370 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:39:16.626755 [debug] [MainThread]: Connection 'test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493' was left open.
[0m19:39:16.627090 [debug] [MainThread]: On test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m19:39:16.738883 [info ] [MainThread]: 
[0m19:39:16.739525 [info ] [MainThread]: Finished running 6 data tests in 0 hours 0 minutes and 2.69 seconds (2.69s).
[0m19:39:16.741256 [debug] [MainThread]: Command end result
[0m19:39:16.771692 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:39:16.773650 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:39:16.780932 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m19:39:16.781289 [info ] [MainThread]: 
[0m19:39:16.782036 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:39:16.782608 [info ] [MainThread]: 
[0m19:39:16.783324 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m19:39:16.784199 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m19:39:16.784834 [info ] [MainThread]: 
[0m19:39:16.785399 [info ] [MainThread]:   compiled code at target/compiled/stock_analysis_project/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m19:39:16.785871 [info ] [MainThread]: 
[0m19:39:16.786360 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m19:39:16.787553 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 4.078694, "process_in_blocks": "0", "process_kernel_time": 0.276645, "process_mem_max_rss": "220980", "process_out_blocks": "2079", "process_user_time": 4.009349}
[0m19:39:16.787936 [debug] [MainThread]: Command `dbt test` failed at 19:39:16.787865 after 4.08 seconds
[0m19:39:16.788263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab4bfb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffab4bde50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff911d1b80>]}
[0m19:39:16.788626 [debug] [MainThread]: Flushing usage events
[0m19:39:17.086923 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:44:21.083052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffae975c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0643a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffae6bc1d0>]}


============================== 19:44:21.090205 | 3831bae3-57cf-4001-adec-2e2f2735dbbb ==============================
[0m19:44:21.090205 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:44:21.090911 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:44:21.906696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3831bae3-57cf-4001-adec-2e2f2735dbbb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb06a19d0>]}
[0m19:44:21.960254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3831bae3-57cf-4001-adec-2e2f2735dbbb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffae2767b0>]}
[0m19:44:21.961496 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:44:22.071800 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:44:22.218978 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:44:22.219904 [debug] [MainThread]: Partial parsing: updated file: stock_analysis_project://models/example/schema.yml
[0m19:44:22.477712 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two schema.yml entries for the same resource named stock_metrics. Resources and their associated columns may only be described a single time. To fix this, remove the resource entry for stock_metrics in one of these files:
   - models/example/schema.yml
  tests/not_null_stock_metrics.yml
[0m19:44:22.479699 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.4435029, "process_in_blocks": "0", "process_kernel_time": 0.3312, "process_mem_max_rss": "208904", "process_out_blocks": "5", "process_user_time": 3.950679}
[0m19:44:22.480862 [debug] [MainThread]: Command `dbt run` failed at 19:44:22.480756 after 1.44 seconds
[0m19:44:22.481288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb2896a20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8c4ac4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8c4aef00>]}
[0m19:44:22.481656 [debug] [MainThread]: Flushing usage events
[0m19:44:22.800313 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:44:45.994617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88ec9c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88e59be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88777d40>]}


============================== 19:44:46.001605 | 4ec0b376-f036-400a-a6cc-1d74218e5e59 ==============================
[0m19:44:46.001605 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:44:46.002486 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:44:46.713187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4ec0b376-f036-400a-a6cc-1d74218e5e59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6c660e60>]}
[0m19:44:46.761053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4ec0b376-f036-400a-a6cc-1d74218e5e59', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6c3112b0>]}
[0m19:44:46.762097 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:44:46.873839 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:44:47.031742 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:44:47.032945 [debug] [MainThread]: Partial parsing: updated file: stock_analysis_project://models/example/schema.yml
[0m19:44:47.254752 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two schema.yml entries for the same resource named stock_metrics. Resources and their associated columns may only be described a single time. To fix this, remove the resource entry for stock_metrics in one of these files:
   - models/example/schema.yml
  tests/not_null_stock_metrics.yml
[0m19:44:47.256386 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.3078976, "process_in_blocks": "0", "process_kernel_time": 0.199488, "process_mem_max_rss": "208956", "process_out_blocks": "5", "process_user_time": 3.677571}
[0m19:44:47.256938 [debug] [MainThread]: Command `dbt run` failed at 19:44:47.256833 after 1.31 seconds
[0m19:44:47.257358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff888e7b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff66ac4170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff67ec1a60>]}
[0m19:44:47.257722 [debug] [MainThread]: Flushing usage events
[0m19:44:47.554445 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:46:31.209711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9328b260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff952a3a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff934bac30>]}


============================== 19:46:31.217774 | 50c309a8-ab3f-4951-a712-08838a833b85 ==============================
[0m19:46:31.217774 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:46:31.218583 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:46:31.931651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff79371f40>]}
[0m19:46:31.980251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff726412b0>]}
[0m19:46:31.981164 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:46:32.097351 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:46:32.253896 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 1 files changed.
[0m19:46:32.254907 [debug] [MainThread]: Partial parsing: updated file: stock_analysis_project://models/example/schema.yml
[0m19:46:32.614499 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m19:46:32.622078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff70ef64e0>]}
[0m19:46:32.704151 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:46:32.706007 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:46:32.727206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff722957c0>]}
[0m19:46:32.727711 [info ] [MainThread]: Found 6 models, 1 snapshot, 6 data tests, 474 macros
[0m19:46:32.728427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff939996a0>]}
[0m19:46:32.730405 [info ] [MainThread]: 
[0m19:46:32.731045 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:46:32.731546 [info ] [MainThread]: 
[0m19:46:32.732288 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:46:32.737568 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m19:46:32.773194 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m19:46:32.773717 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m19:46:32.774103 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:46:33.365312 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.591 seconds
[0m19:46:33.368705 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE, now list_USER_DB_BEETLE_analytics)
[0m19:46:33.378867 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m19:46:33.379281 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m19:46:33.480343 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.101 seconds
[0m19:46:33.484147 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now list_USER_DB_BEETLE_snapshots)
[0m19:46:33.488946 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_snapshots"
[0m19:46:33.489428 [debug] [ThreadPool]: On list_USER_DB_BEETLE_snapshots: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_snapshots"} */
show objects in USER_DB_BEETLE.snapshots limit 10000;
[0m19:46:33.576910 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01bbe342-0305-0ebd-0004-59ff002c160a
[0m19:46:33.577477 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m19:46:33.577934 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m19:46:33.578251 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m19:46:33.579062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff70c65df0>]}
[0m19:46:33.584678 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.moving_avg
[0m19:46:33.585513 [info ] [Thread-1 (]: 1 of 6 START sql view model analytics.moving_avg ............................... [RUN]
[0m19:46:33.586543 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_snapshots, now model.stock_analysis_project.moving_avg)
[0m19:46:33.587105 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.moving_avg
[0m19:46:33.595436 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.moving_avg"
[0m19:46:33.597392 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.moving_avg
[0m19:46:33.629145 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.moving_avg"
[0m19:46:33.630864 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.moving_avg"
[0m19:46:33.631264 [debug] [Thread-1 (]: On model.stock_analysis_project.moving_avg: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.moving_avg"} */
create or replace   view USER_DB_BEETLE.analytics.moving_avg
  
   as (
    SELECT 
  symbol,
  date,
  close,
  AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS moving_avg_7d
FROM USER_DB_BEETLE.raw.stock_data
  );
[0m19:46:33.884978 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.251 seconds
[0m19:46:33.909042 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff952f5a30>]}
[0m19:46:33.909744 [info ] [Thread-1 (]: 1 of 6 OK created sql view model analytics.moving_avg .......................... [[32mSUCCESS 1[0m in 0.32s]
[0m19:46:33.910616 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.moving_avg
[0m19:46:33.911111 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.my_first_dbt_model
[0m19:46:33.911582 [info ] [Thread-1 (]: 2 of 6 START sql table model analytics.my_first_dbt_model ...................... [RUN]
[0m19:46:33.912274 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.moving_avg, now model.stock_analysis_project.my_first_dbt_model)
[0m19:46:33.912586 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.my_first_dbt_model
[0m19:46:33.916782 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.my_first_dbt_model"
[0m19:46:33.918600 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.my_first_dbt_model
[0m19:46:33.941454 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.my_first_dbt_model"
[0m19:46:33.943360 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.my_first_dbt_model"
[0m19:46:33.943957 [debug] [Thread-1 (]: On model.stock_analysis_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.my_first_dbt_model"} */
create or replace transient table USER_DB_BEETLE.analytics.my_first_dbt_model
         as
        (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
        );
[0m19:46:34.903363 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.959 seconds
[0m19:46:34.906763 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff721a8f50>]}
[0m19:46:34.907630 [info ] [Thread-1 (]: 2 of 6 OK created sql table model analytics.my_first_dbt_model ................. [[32mSUCCESS 1[0m in 0.99s]
[0m19:46:34.908875 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.my_first_dbt_model
[0m19:46:34.909352 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.raw_stock_data
[0m19:46:34.910002 [info ] [Thread-1 (]: 3 of 6 START sql view model analytics.raw_stock_data ........................... [RUN]
[0m19:46:34.910905 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.my_first_dbt_model, now model.stock_analysis_project.raw_stock_data)
[0m19:46:34.911306 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.raw_stock_data
[0m19:46:34.913948 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.raw_stock_data"
[0m19:46:34.915194 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.raw_stock_data
[0m19:46:34.918145 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.raw_stock_data"
[0m19:46:34.919469 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.raw_stock_data"
[0m19:46:34.919907 [debug] [Thread-1 (]: On model.stock_analysis_project.raw_stock_data: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.raw_stock_data"} */
create or replace   view USER_DB_BEETLE.analytics.raw_stock_data
  
   as (
    -- models/raw_stock_data.sql
select * from raw.stock_data
  );
[0m19:46:35.305759 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.385 seconds
[0m19:46:35.309368 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff720c3560>]}
[0m19:46:35.310208 [info ] [Thread-1 (]: 3 of 6 OK created sql view model analytics.raw_stock_data ...................... [[32mSUCCESS 1[0m in 0.40s]
[0m19:46:35.311350 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.raw_stock_data
[0m19:46:35.312010 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.rsi
[0m19:46:35.312963 [info ] [Thread-1 (]: 4 of 6 START sql view model analytics.rsi ...................................... [RUN]
[0m19:46:35.314056 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.raw_stock_data, now model.stock_analysis_project.rsi)
[0m19:46:35.314617 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.rsi
[0m19:46:35.317236 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.rsi"
[0m19:46:35.318399 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.rsi
[0m19:46:35.321311 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.rsi"
[0m19:46:35.323417 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.rsi"
[0m19:46:35.323852 [debug] [Thread-1 (]: On model.stock_analysis_project.rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.rsi"} */
create or replace   view USER_DB_BEETLE.analytics.rsi
  
   as (
    WITH gains_losses AS (
  SELECT
    symbol,
    date,
    close,
    close - LAG(close) OVER (PARTITION BY symbol ORDER BY date) AS change
  FROM USER_DB_BEETLE.raw.stock_data
),
rsi_calc AS (
  SELECT *,
    CASE WHEN change > 0 THEN change ELSE 0 END AS gain,
    CASE WHEN change < 0 THEN -change ELSE 0 END AS loss
  FROM gains_losses
)
SELECT
  symbol,
  date,
  AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
  AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss,
  100 - (
    100 / (
      1 + (
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW)
        /
        NULLIF(AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW), 0)
      )
    )
  ) AS rsi
FROM rsi_calc
  );
[0m19:46:35.620942 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.296 seconds
[0m19:46:35.624183 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff721a6570>]}
[0m19:46:35.624837 [info ] [Thread-1 (]: 4 of 6 OK created sql view model analytics.rsi ................................. [[32mSUCCESS 1[0m in 0.31s]
[0m19:46:35.625902 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.rsi
[0m19:46:35.626293 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.my_second_dbt_model
[0m19:46:35.626898 [info ] [Thread-1 (]: 5 of 6 START sql view model analytics.my_second_dbt_model ...................... [RUN]
[0m19:46:35.627578 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.rsi, now model.stock_analysis_project.my_second_dbt_model)
[0m19:46:35.627930 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.my_second_dbt_model
[0m19:46:35.630764 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.my_second_dbt_model"
[0m19:46:35.631927 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.my_second_dbt_model
[0m19:46:35.634446 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.my_second_dbt_model"
[0m19:46:35.635596 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.my_second_dbt_model"
[0m19:46:35.635904 [debug] [Thread-1 (]: On model.stock_analysis_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.my_second_dbt_model"} */
create or replace   view USER_DB_BEETLE.analytics.my_second_dbt_model
  
   as (
    -- Use the `ref` function to select from other models

select *
from USER_DB_BEETLE.analytics.my_first_dbt_model
where id = 1
  );
[0m19:46:35.851279 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.215 seconds
[0m19:46:35.855166 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff70e50410>]}
[0m19:46:35.856056 [info ] [Thread-1 (]: 5 of 6 OK created sql view model analytics.my_second_dbt_model ................. [[32mSUCCESS 1[0m in 0.23s]
[0m19:46:35.857254 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.my_second_dbt_model
[0m19:46:35.857899 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.stock_metrics
[0m19:46:35.858543 [info ] [Thread-1 (]: 6 of 6 START sql view model analytics.stock_metrics ............................ [RUN]
[0m19:46:35.859332 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.my_second_dbt_model, now model.stock_analysis_project.stock_metrics)
[0m19:46:35.859736 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.stock_metrics
[0m19:46:35.863303 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.stock_metrics"
[0m19:46:35.864544 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.stock_metrics
[0m19:46:35.869021 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.stock_metrics"
[0m19:46:35.870537 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.stock_metrics"
[0m19:46:35.870942 [debug] [Thread-1 (]: On model.stock_analysis_project.stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.stock_metrics"} */
create or replace   view USER_DB_BEETLE.analytics.stock_metrics
  
   as (
    -- models/stock_metrics.sql
with raw_data as (
  select *, row_number() over (partition by symbol order by date) as row_num
  from USER_DB_BEETLE.analytics.raw_stock_data
),

calc as (
  select 
    symbol,
    date,
    close,
    avg(close) over (partition by symbol order by date rows between 13 preceding and current row) as ma14,
    avg(close) over (partition by symbol order by date rows between 49 preceding and current row) as ma50
  from raw_data
)

select * from calc
  );
[0m19:46:36.233678 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.362 seconds
[0m19:46:36.237416 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '50c309a8-ab3f-4951-a712-08838a833b85', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9295f0e0>]}
[0m19:46:36.238489 [info ] [Thread-1 (]: 6 of 6 OK created sql view model analytics.stock_metrics ....................... [[32mSUCCESS 1[0m in 0.38s]
[0m19:46:36.239846 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.stock_metrics
[0m19:46:36.241577 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:46:36.242052 [debug] [MainThread]: Connection 'model.stock_analysis_project.stock_metrics' was left open.
[0m19:46:36.242465 [debug] [MainThread]: On model.stock_analysis_project.stock_metrics: Close
[0m19:46:36.323395 [info ] [MainThread]: 
[0m19:46:36.324197 [info ] [MainThread]: Finished running 1 table model, 5 view models in 0 hours 0 minutes and 3.59 seconds (3.59s).
[0m19:46:36.326238 [debug] [MainThread]: Command end result
[0m19:46:36.357976 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:46:36.360114 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:46:36.366009 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m19:46:36.366365 [info ] [MainThread]: 
[0m19:46:36.367117 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:46:36.367674 [info ] [MainThread]: 
[0m19:46:36.368247 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m19:46:36.370087 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.2365966, "process_in_blocks": "0", "process_kernel_time": 0.361042, "process_mem_max_rss": "222932", "process_out_blocks": "3082", "process_user_time": 4.814237}
[0m19:46:36.370618 [debug] [MainThread]: Command `dbt run` succeeded at 19:46:36.370504 after 5.24 seconds
[0m19:46:36.371135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff935480b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff793e9520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff724c2570>]}
[0m19:46:36.371487 [debug] [MainThread]: Flushing usage events
[0m19:46:36.765572 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:46:39.371618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e2b14f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d5a4320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d5a5130>]}


============================== 19:46:39.378614 | 8cd76148-c573-4ad2-9790-8a846a2c31b0 ==============================
[0m19:46:39.378614 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:46:39.379535 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:46:40.117593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8cd76148-c573-4ad2-9790-8a846a2c31b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff62a42a20>]}
[0m19:46:40.213315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8cd76148-c573-4ad2-9790-8a846a2c31b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7eca23c0>]}
[0m19:46:40.215196 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:46:40.344255 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:46:40.490997 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:46:40.491452 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:46:40.497114 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m19:46:40.541169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8cd76148-c573-4ad2-9790-8a846a2c31b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff60e275c0>]}
[0m19:46:40.651111 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:46:40.654763 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:46:40.702336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8cd76148-c573-4ad2-9790-8a846a2c31b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6097a420>]}
[0m19:46:40.702912 [info ] [MainThread]: Found 6 models, 1 snapshot, 6 data tests, 474 macros
[0m19:46:40.703646 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8cd76148-c573-4ad2-9790-8a846a2c31b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff609454f0>]}
[0m19:46:40.705432 [info ] [MainThread]: 
[0m19:46:40.706014 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:46:40.706496 [info ] [MainThread]: 
[0m19:46:40.707286 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:46:40.712396 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE_snapshots'
[0m19:46:40.751288 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_snapshots"
[0m19:46:40.751995 [debug] [ThreadPool]: On list_USER_DB_BEETLE_snapshots: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_snapshots"} */
show objects in USER_DB_BEETLE.snapshots limit 10000;
[0m19:46:40.752425 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:46:41.166537 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01bbe342-0305-0bb1-0004-59ff002c30d6
[0m19:46:41.167077 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m19:46:41.167521 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m19:46:41.167856 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m19:46:41.168481 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_snapshots, now list_USER_DB_BEETLE_analytics)
[0m19:46:41.170921 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m19:46:41.171262 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m19:46:41.265636 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.094 seconds
[0m19:46:41.271789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8cd76148-c573-4ad2-9790-8a846a2c31b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff607a82c0>]}
[0m19:46:41.277318 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:46:41.278303 [info ] [Thread-1 (]: 1 of 6 START test not_null_my_first_dbt_model_id ............................... [RUN]
[0m19:46:41.279236 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710)
[0m19:46:41.279631 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:46:41.301653 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m19:46:41.303183 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:46:41.326242 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m19:46:41.328089 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710"
[0m19:46:41.328597 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from USER_DB_BEETLE.analytics.my_first_dbt_model
where id is null



      
    ) dbt_internal_test
[0m19:46:41.668667 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.339 seconds
[0m19:46:41.679973 [error] [Thread-1 (]: 1 of 6 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 0.40s]
[0m19:46:41.681331 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710
[0m19:46:41.681883 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778
[0m19:46:41.682379 [info ] [Thread-1 (]: 2 of 6 START test not_null_my_second_dbt_model_id .............................. [RUN]
[0m19:46:41.683189 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.not_null_my_first_dbt_model_id.5fb22c2710, now test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778)
[0m19:46:41.683843 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778
[0m19:46:41.688125 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778"
[0m19:46:41.689194 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778
[0m19:46:41.691385 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778"
[0m19:46:41.692661 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778"
[0m19:46:41.693170 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from USER_DB_BEETLE.analytics.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
[0m19:46:42.105452 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.412 seconds
[0m19:46:42.108995 [info ] [Thread-1 (]: 2 of 6 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 0.43s]
[0m19:46:42.110292 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778
[0m19:46:42.110828 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:46:42.111377 [info ] [Thread-1 (]: 3 of 6 START test not_null_stock_metrics_close ................................. [RUN]
[0m19:46:42.112273 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.not_null_my_second_dbt_model_id.151b76d778, now test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c)
[0m19:46:42.112927 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:46:42.118095 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:46:42.119448 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:46:42.121868 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:46:42.123087 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:46:42.123459 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select close
from USER_DB_BEETLE.analytics.stock_metrics
where close is null



      
    ) dbt_internal_test
[0m19:46:42.364205 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.240 seconds
[0m19:46:42.366912 [info ] [Thread-1 (]: 3 of 6 PASS not_null_stock_metrics_close ....................................... [[32mPASS[0m in 0.25s]
[0m19:46:42.368205 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:46:42.368701 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:46:42.369136 [info ] [Thread-1 (]: 4 of 6 START test not_null_stock_metrics_symbol ................................ [RUN]
[0m19:46:42.369910 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c, now test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7)
[0m19:46:42.370298 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:46:42.374305 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:46:42.375491 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:46:42.377675 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:46:42.378960 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:46:42.379311 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from USER_DB_BEETLE.analytics.stock_metrics
where symbol is null



      
    ) dbt_internal_test
[0m19:46:42.691938 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.312 seconds
[0m19:46:42.694493 [info ] [Thread-1 (]: 4 of 6 PASS not_null_stock_metrics_symbol ...................................... [[32mPASS[0m in 0.32s]
[0m19:46:42.695533 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:46:42.695928 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321
[0m19:46:42.696391 [info ] [Thread-1 (]: 5 of 6 START test unique_my_first_dbt_model_id ................................. [RUN]
[0m19:46:42.697126 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7, now test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321)
[0m19:46:42.697494 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321
[0m19:46:42.703831 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321"
[0m19:46:42.704890 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321
[0m19:46:42.707021 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321"
[0m19:46:42.708199 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321"
[0m19:46:42.710276 [debug] [Thread-1 (]: On test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from USER_DB_BEETLE.analytics.my_first_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:46:42.803936 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.093 seconds
[0m19:46:42.806519 [info ] [Thread-1 (]: 5 of 6 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 0.11s]
[0m19:46:42.807551 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321
[0m19:46:42.808017 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493
[0m19:46:42.808535 [info ] [Thread-1 (]: 6 of 6 START test unique_my_second_dbt_model_id ................................ [RUN]
[0m19:46:42.809311 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.unique_my_first_dbt_model_id.16e066b321, now test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493)
[0m19:46:42.809781 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493
[0m19:46:42.813771 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m19:46:42.814708 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493
[0m19:46:42.816819 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m19:46:42.817943 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493"
[0m19:46:42.818261 [debug] [Thread-1 (]: On test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from USER_DB_BEETLE.analytics.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
[0m19:46:42.980305 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.162 seconds
[0m19:46:42.983500 [info ] [Thread-1 (]: 6 of 6 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 0.17s]
[0m19:46:42.984703 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493
[0m19:46:42.986220 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:46:42.986575 [debug] [MainThread]: Connection 'test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493' was left open.
[0m19:46:42.986916 [debug] [MainThread]: On test.stock_analysis_project.unique_my_second_dbt_model_id.57a0f8c493: Close
[0m19:46:43.090669 [info ] [MainThread]: 
[0m19:46:43.091599 [info ] [MainThread]: Finished running 6 data tests in 0 hours 0 minutes and 2.38 seconds (2.38s).
[0m19:46:43.093297 [debug] [MainThread]: Command end result
[0m19:46:43.120397 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:46:43.122152 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:46:43.129110 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m19:46:43.129418 [info ] [MainThread]: 
[0m19:46:43.130149 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:46:43.130674 [info ] [MainThread]: 
[0m19:46:43.131528 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
[0m19:46:43.132673 [error] [MainThread]:   Got 1 result, configured to fail if != 0
[0m19:46:43.133323 [info ] [MainThread]: 
[0m19:46:43.133851 [info ] [MainThread]:   compiled code at target/compiled/stock_analysis_project/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
[0m19:46:43.134316 [info ] [MainThread]: 
[0m19:46:43.134753 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m19:46:43.135875 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": false, "command_wall_clock_time": 3.8089314, "process_in_blocks": "0", "process_kernel_time": 0.27412, "process_mem_max_rss": "221120", "process_out_blocks": "2080", "process_user_time": 4.191844}
[0m19:46:43.136317 [debug] [MainThread]: Command `dbt test` failed at 19:46:43.136222 after 3.81 seconds
[0m19:46:43.136654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7d707c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff64936ba0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff60df1c10>]}
[0m19:46:43.136954 [debug] [MainThread]: Flushing usage events
[0m19:46:43.434305 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:49:10.773431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffba11ce30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffba67cb60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffba87cbf0>]}


============================== 19:49:10.781764 | a6c323ad-82d4-4a47-a9cd-854005aa6bfb ==============================
[0m19:49:10.781764 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:49:10.782671 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:49:11.616952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a6c323ad-82d4-4a47-a9cd-854005aa6bfb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a85f4d0>]}
[0m19:49:11.683743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a6c323ad-82d4-4a47-a9cd-854005aa6bfb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb9f2eed0>]}
[0m19:49:11.684823 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:49:11.810411 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:49:11.993188 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 0 files added, 1 files changed.
[0m19:49:11.994210 [debug] [MainThread]: Partial parsing: updated file: stock_analysis_project://models/example/schema.yml
[0m19:49:11.994588 [debug] [MainThread]: Partial parsing: deleted file: stock_analysis_project://models/example/my_second_dbt_model.sql
[0m19:49:11.994964 [debug] [MainThread]: Partial parsing: deleted file: stock_analysis_project://models/example/my_first_dbt_model.sql
[0m19:49:12.135067 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m19:49:12.147670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a6c323ad-82d4-4a47-a9cd-854005aa6bfb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9953f710>]}
[0m19:49:12.351942 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:49:12.357221 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:49:12.406243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a6c323ad-82d4-4a47-a9cd-854005aa6bfb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99785670>]}
[0m19:49:12.407634 [info ] [MainThread]: Found 4 models, 1 snapshot, 2 data tests, 474 macros
[0m19:49:12.409434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6c323ad-82d4-4a47-a9cd-854005aa6bfb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99a1a570>]}
[0m19:49:12.414567 [info ] [MainThread]: 
[0m19:49:12.416215 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:49:12.417468 [info ] [MainThread]: 
[0m19:49:12.419283 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:49:12.430306 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m19:49:12.511520 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m19:49:12.512582 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m19:49:12.513420 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:49:13.015363 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.502 seconds
[0m19:49:13.020986 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE, now list_USER_DB_BEETLE_snapshots)
[0m19:49:13.036317 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_snapshots"
[0m19:49:13.036877 [debug] [ThreadPool]: On list_USER_DB_BEETLE_snapshots: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_snapshots"} */
show objects in USER_DB_BEETLE.snapshots limit 10000;
[0m19:49:13.119099 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01bbe345-0305-0bd9-0004-59ff002c0fde
[0m19:49:13.119529 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m19:49:13.119971 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m19:49:13.120348 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m19:49:13.120905 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_snapshots, now list_USER_DB_BEETLE_analytics)
[0m19:49:13.123139 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m19:49:13.123519 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m19:49:13.257353 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.133 seconds
[0m19:49:13.263717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a6c323ad-82d4-4a47-a9cd-854005aa6bfb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99a22570>]}
[0m19:49:13.269700 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.moving_avg
[0m19:49:13.270572 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics.moving_avg ............................... [RUN]
[0m19:49:13.271172 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now model.stock_analysis_project.moving_avg)
[0m19:49:13.271562 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.moving_avg
[0m19:49:13.278141 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.moving_avg"
[0m19:49:13.280570 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.moving_avg
[0m19:49:13.308281 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.moving_avg"
[0m19:49:13.310061 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.moving_avg"
[0m19:49:13.310415 [debug] [Thread-1 (]: On model.stock_analysis_project.moving_avg: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.moving_avg"} */
create or replace   view USER_DB_BEETLE.analytics.moving_avg
  
   as (
    SELECT 
  symbol,
  date,
  close,
  AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS moving_avg_7d
FROM USER_DB_BEETLE.raw.stock_data
  );
[0m19:49:13.962162 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.651 seconds
[0m19:49:13.989524 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6c323ad-82d4-4a47-a9cd-854005aa6bfb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbc8558b0>]}
[0m19:49:13.990380 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics.moving_avg .......................... [[32mSUCCESS 1[0m in 0.72s]
[0m19:49:13.991409 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.moving_avg
[0m19:49:13.991902 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.raw_stock_data
[0m19:49:13.993017 [info ] [Thread-1 (]: 2 of 4 START sql view model analytics.raw_stock_data ........................... [RUN]
[0m19:49:13.993829 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.moving_avg, now model.stock_analysis_project.raw_stock_data)
[0m19:49:13.994333 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.raw_stock_data
[0m19:49:13.996169 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.raw_stock_data"
[0m19:49:13.998214 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.raw_stock_data
[0m19:49:14.001100 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.raw_stock_data"
[0m19:49:14.002494 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.raw_stock_data"
[0m19:49:14.002902 [debug] [Thread-1 (]: On model.stock_analysis_project.raw_stock_data: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.raw_stock_data"} */
create or replace   view USER_DB_BEETLE.analytics.raw_stock_data
  
   as (
    -- models/raw_stock_data.sql
select * from raw.stock_data
  );
[0m19:49:14.235424 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.232 seconds
[0m19:49:14.239743 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6c323ad-82d4-4a47-a9cd-854005aa6bfb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbc292f60>]}
[0m19:49:14.240841 [info ] [Thread-1 (]: 2 of 4 OK created sql view model analytics.raw_stock_data ...................... [[32mSUCCESS 1[0m in 0.25s]
[0m19:49:14.242040 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.raw_stock_data
[0m19:49:14.242554 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.rsi
[0m19:49:14.243184 [info ] [Thread-1 (]: 3 of 4 START sql view model analytics.rsi ...................................... [RUN]
[0m19:49:14.243698 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.raw_stock_data, now model.stock_analysis_project.rsi)
[0m19:49:14.244168 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.rsi
[0m19:49:14.246599 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.rsi"
[0m19:49:14.248584 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.rsi
[0m19:49:14.251441 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.rsi"
[0m19:49:14.253698 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.rsi"
[0m19:49:14.254137 [debug] [Thread-1 (]: On model.stock_analysis_project.rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.rsi"} */
create or replace   view USER_DB_BEETLE.analytics.rsi
  
   as (
    WITH gains_losses AS (
  SELECT
    symbol,
    date,
    close,
    close - LAG(close) OVER (PARTITION BY symbol ORDER BY date) AS change
  FROM USER_DB_BEETLE.raw.stock_data
),
rsi_calc AS (
  SELECT *,
    CASE WHEN change > 0 THEN change ELSE 0 END AS gain,
    CASE WHEN change < 0 THEN -change ELSE 0 END AS loss
  FROM gains_losses
)
SELECT
  symbol,
  date,
  AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
  AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss,
  100 - (
    100 / (
      1 + (
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW)
        /
        NULLIF(AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW), 0)
      )
    )
  ) AS rsi
FROM rsi_calc
  );
[0m19:49:14.534354 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.279 seconds
[0m19:49:14.538295 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6c323ad-82d4-4a47-a9cd-854005aa6bfb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff98797500>]}
[0m19:49:14.539031 [info ] [Thread-1 (]: 3 of 4 OK created sql view model analytics.rsi ................................. [[32mSUCCESS 1[0m in 0.29s]
[0m19:49:14.539952 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.rsi
[0m19:49:14.540415 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.stock_metrics
[0m19:49:14.540976 [info ] [Thread-1 (]: 4 of 4 START sql view model analytics.stock_metrics ............................ [RUN]
[0m19:49:14.541589 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.rsi, now model.stock_analysis_project.stock_metrics)
[0m19:49:14.541970 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.stock_metrics
[0m19:49:14.545576 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.stock_metrics"
[0m19:49:14.547322 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.stock_metrics
[0m19:49:14.550230 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.stock_metrics"
[0m19:49:14.551880 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.stock_metrics"
[0m19:49:14.552246 [debug] [Thread-1 (]: On model.stock_analysis_project.stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.stock_metrics"} */
create or replace   view USER_DB_BEETLE.analytics.stock_metrics
  
   as (
    -- models/stock_metrics.sql
with raw_data as (
  select *, row_number() over (partition by symbol order by date) as row_num
  from USER_DB_BEETLE.analytics.raw_stock_data
),

calc as (
  select 
    symbol,
    date,
    close,
    avg(close) over (partition by symbol order by date rows between 13 preceding and current row) as ma14,
    avg(close) over (partition by symbol order by date rows between 49 preceding and current row) as ma50
  from raw_data
)

select * from calc
  );
[0m19:49:14.816716 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.264 seconds
[0m19:49:14.821230 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a6c323ad-82d4-4a47-a9cd-854005aa6bfb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff987859d0>]}
[0m19:49:14.822289 [info ] [Thread-1 (]: 4 of 4 OK created sql view model analytics.stock_metrics ....................... [[32mSUCCESS 1[0m in 0.28s]
[0m19:49:14.823508 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.stock_metrics
[0m19:49:14.825179 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:49:14.825645 [debug] [MainThread]: Connection 'model.stock_analysis_project.stock_metrics' was left open.
[0m19:49:14.826041 [debug] [MainThread]: On model.stock_analysis_project.stock_metrics: Close
[0m19:49:14.935403 [info ] [MainThread]: 
[0m19:49:14.936674 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 2.52 seconds (2.52s).
[0m19:49:14.938447 [debug] [MainThread]: Command end result
[0m19:49:15.067517 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:49:15.069663 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:49:15.076551 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m19:49:15.076966 [info ] [MainThread]: 
[0m19:49:15.077686 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:49:15.078348 [info ] [MainThread]: 
[0m19:49:15.079272 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m19:49:15.080823 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.3551574, "process_in_blocks": "0", "process_kernel_time": 0.343437, "process_mem_max_rss": "219040", "process_out_blocks": "2979", "process_user_time": 4.595848}
[0m19:49:15.081326 [debug] [MainThread]: Command `dbt run` succeeded at 19:49:15.081216 after 4.36 seconds
[0m19:49:15.081714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffba2c74d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99b39970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbcdca750>]}
[0m19:49:15.082135 [debug] [MainThread]: Flushing usage events
[0m19:49:15.502376 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:49:18.032996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff95375e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff95375dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9534cbf0>]}


============================== 19:49:18.039981 | 13272771-de7b-4215-92e6-5153f9b300c2 ==============================
[0m19:49:18.039981 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:49:18.040850 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:49:18.767686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '13272771-de7b-4215-92e6-5153f9b300c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff976799a0>]}
[0m19:49:18.816305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '13272771-de7b-4215-92e6-5153f9b300c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff788fffb0>]}
[0m19:49:18.817200 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:49:18.952967 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:49:19.097547 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:49:19.098072 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:49:19.103389 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m19:49:19.145427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '13272771-de7b-4215-92e6-5153f9b300c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7aec98b0>]}
[0m19:49:19.230707 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:49:19.232890 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:49:19.264812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '13272771-de7b-4215-92e6-5153f9b300c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff782cd550>]}
[0m19:49:19.265384 [info ] [MainThread]: Found 4 models, 1 snapshot, 2 data tests, 474 macros
[0m19:49:19.266139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '13272771-de7b-4215-92e6-5153f9b300c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff782a4230>]}
[0m19:49:19.267970 [info ] [MainThread]: 
[0m19:49:19.268516 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:49:19.269008 [info ] [MainThread]: 
[0m19:49:19.269596 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:49:19.274284 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE_snapshots'
[0m19:49:19.311609 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_snapshots"
[0m19:49:19.312166 [debug] [ThreadPool]: On list_USER_DB_BEETLE_snapshots: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_snapshots"} */
show objects in USER_DB_BEETLE.snapshots limit 10000;
[0m19:49:19.312546 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:49:19.733529 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01bbe345-0305-0c98-0004-59ff002c216e
[0m19:49:19.734092 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
[0m19:49:19.734553 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
[0m19:49:19.734938 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
[0m19:49:19.735516 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_snapshots, now list_USER_DB_BEETLE_analytics)
[0m19:49:19.738104 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m19:49:19.738417 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m19:49:19.859266 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.120 seconds
[0m19:49:19.864591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '13272771-de7b-4215-92e6-5153f9b300c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff784cc230>]}
[0m19:49:19.869471 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:49:19.870233 [info ] [Thread-1 (]: 1 of 2 START test not_null_stock_metrics_close ................................. [RUN]
[0m19:49:19.871456 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c)
[0m19:49:19.871977 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:49:19.888295 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:49:19.890223 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:49:19.911843 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:49:19.913590 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:49:19.914064 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select close
from USER_DB_BEETLE.analytics.stock_metrics
where close is null



      
    ) dbt_internal_test
[0m19:49:20.094446 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.180 seconds
[0m19:49:20.106577 [info ] [Thread-1 (]: 1 of 2 PASS not_null_stock_metrics_close ....................................... [[32mPASS[0m in 0.24s]
[0m19:49:20.108021 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:49:20.108629 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:49:20.109143 [info ] [Thread-1 (]: 2 of 2 START test not_null_stock_metrics_symbol ................................ [RUN]
[0m19:49:20.109830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c, now test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7)
[0m19:49:20.110367 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:49:20.114509 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:49:20.115944 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:49:20.120003 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:49:20.122663 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:49:20.123413 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from USER_DB_BEETLE.analytics.stock_metrics
where symbol is null



      
    ) dbt_internal_test
[0m19:49:20.291631 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.168 seconds
[0m19:49:20.294485 [info ] [Thread-1 (]: 2 of 2 PASS not_null_stock_metrics_symbol ...................................... [[32mPASS[0m in 0.18s]
[0m19:49:20.295471 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:49:20.296851 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:49:20.297179 [debug] [MainThread]: Connection 'test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7' was left open.
[0m19:49:20.297561 [debug] [MainThread]: On test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7: Close
[0m19:49:20.402581 [info ] [MainThread]: 
[0m19:49:20.403429 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 1.13 seconds (1.13s).
[0m19:49:20.404529 [debug] [MainThread]: Command end result
[0m19:49:20.435283 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:49:20.437545 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:49:20.444713 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m19:49:20.445084 [info ] [MainThread]: 
[0m19:49:20.445812 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:49:20.446334 [info ] [MainThread]: 
[0m19:49:20.446944 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m19:49:20.448521 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.4617095, "process_in_blocks": "0", "process_kernel_time": 0.230526, "process_mem_max_rss": "220704", "process_out_blocks": "1981", "process_user_time": 3.955026}
[0m19:49:20.448963 [debug] [MainThread]: Command `dbt test` succeeded at 19:49:20.448872 after 2.46 seconds
[0m19:49:20.449350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff965b7140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff73353e60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff78779e20>]}
[0m19:49:20.449702 [debug] [MainThread]: Flushing usage events
[0m19:49:20.757846 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:49:23.536315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8991d850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff87293f20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86f24a70>]}


============================== 19:49:23.544989 | 5c3ea629-d537-4f4d-b0bd-77ab89bdb0c6 ==============================
[0m19:49:23.544989 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:49:23.546280 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt snapshot --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:49:24.231522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5c3ea629-d537-4f4d-b0bd-77ab89bdb0c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86c83b30>]}
[0m19:49:24.270125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5c3ea629-d537-4f4d-b0bd-77ab89bdb0c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6692bd70>]}
[0m19:49:24.270990 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:49:24.366436 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:49:24.527229 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:49:24.527771 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:49:24.533254 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m19:49:24.574567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5c3ea629-d537-4f4d-b0bd-77ab89bdb0c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff667a72c0>]}
[0m19:49:24.665160 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:49:24.667288 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:49:24.687868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5c3ea629-d537-4f4d-b0bd-77ab89bdb0c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff66333b90>]}
[0m19:49:24.688420 [info ] [MainThread]: Found 4 models, 1 snapshot, 2 data tests, 474 macros
[0m19:49:24.689113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c3ea629-d537-4f4d-b0bd-77ab89bdb0c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff664da720>]}
[0m19:49:24.690998 [info ] [MainThread]: 
[0m19:49:24.691586 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:49:24.692122 [info ] [MainThread]: 
[0m19:49:24.693037 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:49:24.694020 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m19:49:24.728487 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m19:49:24.729013 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m19:49:24.729344 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:49:25.116182 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 0.387 seconds
[0m19:49:25.118327 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE, now create_USER_DB_BEETLE_snapshots)
[0m19:49:25.118863 [debug] [ThreadPool]: Creating schema "database: "USER_DB_BEETLE"
schema: "snapshots"
"
[0m19:49:25.123669 [debug] [ThreadPool]: Using snowflake connection "create_USER_DB_BEETLE_snapshots"
[0m19:49:25.124083 [debug] [ThreadPool]: On create_USER_DB_BEETLE_snapshots: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "create_USER_DB_BEETLE_snapshots"} */
create schema if not exists USER_DB_BEETLE.snapshots
[0m19:49:25.247460 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.123 seconds
[0m19:49:25.256147 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_USER_DB_BEETLE_snapshots, now list_USER_DB_BEETLE_snapshots)
[0m19:49:25.267060 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_snapshots"
[0m19:49:25.267514 [debug] [ThreadPool]: On list_USER_DB_BEETLE_snapshots: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_snapshots"} */
show objects in USER_DB_BEETLE.snapshots limit 10000;
[0m19:49:25.368320 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 0.100 seconds
[0m19:49:25.372429 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_snapshots, now list_USER_DB_BEETLE_analytics)
[0m19:49:25.376697 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m19:49:25.377494 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m19:49:25.494330 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.116 seconds
[0m19:49:25.500041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c3ea629-d537-4f4d-b0bd-77ab89bdb0c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff663b42f0>]}
[0m19:49:25.505072 [debug] [Thread-1 (]: Began running node snapshot.stock_analysis_project.stock_snapshot
[0m19:49:25.505910 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.stock_snapshot ................................. [RUN]
[0m19:49:25.506858 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now snapshot.stock_analysis_project.stock_snapshot)
[0m19:49:25.507280 [debug] [Thread-1 (]: Began compiling node snapshot.stock_analysis_project.stock_snapshot
[0m19:49:25.515672 [debug] [Thread-1 (]: Began executing node snapshot.stock_analysis_project.stock_snapshot
[0m19:49:25.598925 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:49:25.599550 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
/* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
select * from (
        
    

    select *,
        md5(coalesce(cast(symbol || date as varchar ), '')
         || '|' || coalesce(cast(to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as varchar ), '')
        ) as dbt_scd_id,
        to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_updated_at,
        to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_valid_from,
        
  
  coalesce(nullif(to_timestamp_ntz(convert_timezone('UTC', current_timestamp())), to_timestamp_ntz(convert_timezone('UTC', current_timestamp()))), null)
  as dbt_valid_to
from (
        


select * from USER_DB_BEETLE.analytics.raw_stock_data

    ) sbq



    ) as __dbt_sbq
    where false
    limit 0
[0m19:49:25.903975 [debug] [Thread-1 (]: SQL status: SUCCESS 0 in 0.304 seconds
[0m19:49:25.909228 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:49:25.909765 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
/* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
select * from (
        select to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0
[0m19:49:25.983579 [debug] [Thread-1 (]: SQL status: SUCCESS 0 in 0.073 seconds
[0m19:49:25.985046 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.stock_analysis_project.stock_snapshot"
[0m19:49:25.989078 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:49:25.990003 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
create or replace transient table USER_DB_BEETLE.snapshots.stock_snapshot
         as
        (
    

    select *,
        md5(coalesce(cast(symbol || date as varchar ), '')
         || '|' || coalesce(cast(to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as varchar ), '')
        ) as dbt_scd_id,
        to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_updated_at,
        to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_valid_from,
        
  
  coalesce(nullif(to_timestamp_ntz(convert_timezone('UTC', current_timestamp())), to_timestamp_ntz(convert_timezone('UTC', current_timestamp()))), null)
  as dbt_valid_to
from (
        


select * from USER_DB_BEETLE.analytics.raw_stock_data

    ) sbq



        );
[0m19:49:26.907536 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.917 seconds
[0m19:49:26.936919 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c3ea629-d537-4f4d-b0bd-77ab89bdb0c6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff65641610>]}
[0m19:49:26.937912 [info ] [Thread-1 (]: 1 of 1 OK snapshotted snapshots.stock_snapshot ................................. [[32mSUCCESS 1[0m in 1.43s]
[0m19:49:26.938917 [debug] [Thread-1 (]: Finished running node snapshot.stock_analysis_project.stock_snapshot
[0m19:49:26.940350 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:49:26.940740 [debug] [MainThread]: Connection 'snapshot.stock_analysis_project.stock_snapshot' was left open.
[0m19:49:26.941115 [debug] [MainThread]: On snapshot.stock_analysis_project.stock_snapshot: Close
[0m19:49:27.040233 [info ] [MainThread]: 
[0m19:49:27.041553 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 2.35 seconds (2.35s).
[0m19:49:27.043059 [debug] [MainThread]: Command end result
[0m19:49:27.072511 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:49:27.074818 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:49:27.081134 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m19:49:27.081479 [info ] [MainThread]: 
[0m19:49:27.082205 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:49:27.082673 [info ] [MainThread]: 
[0m19:49:27.083101 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:49:27.085159 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 3.5958893, "process_in_blocks": "0", "process_kernel_time": 0.226212, "process_mem_max_rss": "218596", "process_out_blocks": "1979", "process_user_time": 4.252397}
[0m19:49:27.085738 [debug] [MainThread]: Command `dbt snapshot` succeeded at 19:49:27.085614 after 3.60 seconds
[0m19:49:27.086269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8743c1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6698c620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6698cb30>]}
[0m19:49:27.086628 [debug] [MainThread]: Flushing usage events
[0m19:49:27.422883 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:50:17.387803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa48572c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3abab40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa452bd40>]}


============================== 19:50:17.394789 | eaba47b7-d82b-4001-a68a-2d31e8d48f28 ==============================
[0m19:50:17.394789 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:50:17.395738 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:50:18.117073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eaba47b7-d82b-4001-a68a-2d31e8d48f28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff884c9b50>]}
[0m19:50:18.171034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eaba47b7-d82b-4001-a68a-2d31e8d48f28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa43b9c10>]}
[0m19:50:18.172072 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:50:18.282864 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:50:18.425461 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:50:18.425944 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:50:18.431195 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m19:50:18.472562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eaba47b7-d82b-4001-a68a-2d31e8d48f28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff834a2930>]}
[0m19:50:18.570583 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:50:18.573078 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:50:18.594429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eaba47b7-d82b-4001-a68a-2d31e8d48f28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff834a0bf0>]}
[0m19:50:18.594954 [info ] [MainThread]: Found 4 models, 1 snapshot, 2 data tests, 474 macros
[0m19:50:18.595614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eaba47b7-d82b-4001-a68a-2d31e8d48f28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff837bd070>]}
[0m19:50:18.597581 [info ] [MainThread]: 
[0m19:50:18.598147 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:50:18.598624 [info ] [MainThread]: 
[0m19:50:18.599353 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:50:18.604217 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m19:50:18.639631 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m19:50:18.640185 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m19:50:18.640616 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:50:19.034997 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.394 seconds
[0m19:50:19.038076 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE, now list_USER_DB_BEETLE_snapshots)
[0m19:50:19.048136 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_snapshots"
[0m19:50:19.048549 [debug] [ThreadPool]: On list_USER_DB_BEETLE_snapshots: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_snapshots"} */
show objects in USER_DB_BEETLE.snapshots limit 10000;
[0m19:50:19.162313 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.113 seconds
[0m19:50:19.165393 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_snapshots, now list_USER_DB_BEETLE_analytics)
[0m19:50:19.169205 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m19:50:19.169816 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m19:50:19.277233 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.107 seconds
[0m19:50:19.283281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eaba47b7-d82b-4001-a68a-2d31e8d48f28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8362c830>]}
[0m19:50:19.288597 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.moving_avg
[0m19:50:19.289527 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics.moving_avg ............................... [RUN]
[0m19:50:19.290492 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now model.stock_analysis_project.moving_avg)
[0m19:50:19.290930 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.moving_avg
[0m19:50:19.299616 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.moving_avg"
[0m19:50:19.301308 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.moving_avg
[0m19:50:19.333417 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.moving_avg"
[0m19:50:19.335106 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.moving_avg"
[0m19:50:19.335565 [debug] [Thread-1 (]: On model.stock_analysis_project.moving_avg: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.moving_avg"} */
create or replace   view USER_DB_BEETLE.analytics.moving_avg
  
   as (
    SELECT 
  symbol,
  date,
  close,
  AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 6 PRECEDING AND CURRENT ROW) AS moving_avg_7d
FROM USER_DB_BEETLE.raw.stock_data
  );
[0m19:50:19.579722 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.244 seconds
[0m19:50:19.611628 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eaba47b7-d82b-4001-a68a-2d31e8d48f28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82282660>]}
[0m19:50:19.612549 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics.moving_avg .......................... [[32mSUCCESS 1[0m in 0.32s]
[0m19:50:19.613637 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.moving_avg
[0m19:50:19.614113 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.raw_stock_data
[0m19:50:19.614690 [info ] [Thread-1 (]: 2 of 4 START sql view model analytics.raw_stock_data ........................... [RUN]
[0m19:50:19.615387 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.moving_avg, now model.stock_analysis_project.raw_stock_data)
[0m19:50:19.615765 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.raw_stock_data
[0m19:50:19.617669 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.raw_stock_data"
[0m19:50:19.618689 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.raw_stock_data
[0m19:50:19.622554 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.raw_stock_data"
[0m19:50:19.623572 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.raw_stock_data"
[0m19:50:19.624216 [debug] [Thread-1 (]: On model.stock_analysis_project.raw_stock_data: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.raw_stock_data"} */
create or replace   view USER_DB_BEETLE.analytics.raw_stock_data
  
   as (
    -- models/raw_stock_data.sql
select * from raw.stock_data
  );
[0m19:50:19.895558 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.271 seconds
[0m19:50:19.898809 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eaba47b7-d82b-4001-a68a-2d31e8d48f28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff822e4a40>]}
[0m19:50:19.899810 [info ] [Thread-1 (]: 2 of 4 OK created sql view model analytics.raw_stock_data ...................... [[32mSUCCESS 1[0m in 0.28s]
[0m19:50:19.901240 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.raw_stock_data
[0m19:50:19.901863 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.rsi
[0m19:50:19.902571 [info ] [Thread-1 (]: 3 of 4 START sql view model analytics.rsi ...................................... [RUN]
[0m19:50:19.903232 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.raw_stock_data, now model.stock_analysis_project.rsi)
[0m19:50:19.903640 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.rsi
[0m19:50:19.905367 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.rsi"
[0m19:50:19.906375 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.rsi
[0m19:50:19.909533 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.rsi"
[0m19:50:19.911294 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.rsi"
[0m19:50:19.911729 [debug] [Thread-1 (]: On model.stock_analysis_project.rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.rsi"} */
create or replace   view USER_DB_BEETLE.analytics.rsi
  
   as (
    WITH gains_losses AS (
  SELECT
    symbol,
    date,
    close,
    close - LAG(close) OVER (PARTITION BY symbol ORDER BY date) AS change
  FROM USER_DB_BEETLE.raw.stock_data
),
rsi_calc AS (
  SELECT *,
    CASE WHEN change > 0 THEN change ELSE 0 END AS gain,
    CASE WHEN change < 0 THEN -change ELSE 0 END AS loss
  FROM gains_losses
)
SELECT
  symbol,
  date,
  AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
  AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss,
  100 - (
    100 / (
      1 + (
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW)
        /
        NULLIF(AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW), 0)
      )
    )
  ) AS rsi
FROM rsi_calc
  );
[0m19:50:20.113640 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.201 seconds
[0m19:50:20.116272 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eaba47b7-d82b-4001-a68a-2d31e8d48f28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff822b0680>]}
[0m19:50:20.117011 [info ] [Thread-1 (]: 3 of 4 OK created sql view model analytics.rsi ................................. [[32mSUCCESS 1[0m in 0.21s]
[0m19:50:20.118012 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.rsi
[0m19:50:20.118544 [debug] [Thread-1 (]: Began running node model.stock_analysis_project.stock_metrics
[0m19:50:20.119070 [info ] [Thread-1 (]: 4 of 4 START sql view model analytics.stock_metrics ............................ [RUN]
[0m19:50:20.119620 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.stock_analysis_project.rsi, now model.stock_analysis_project.stock_metrics)
[0m19:50:20.120012 [debug] [Thread-1 (]: Began compiling node model.stock_analysis_project.stock_metrics
[0m19:50:20.122712 [debug] [Thread-1 (]: Writing injected SQL for node "model.stock_analysis_project.stock_metrics"
[0m19:50:20.123746 [debug] [Thread-1 (]: Began executing node model.stock_analysis_project.stock_metrics
[0m19:50:20.126318 [debug] [Thread-1 (]: Writing runtime sql for node "model.stock_analysis_project.stock_metrics"
[0m19:50:20.127695 [debug] [Thread-1 (]: Using snowflake connection "model.stock_analysis_project.stock_metrics"
[0m19:50:20.128038 [debug] [Thread-1 (]: On model.stock_analysis_project.stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "model.stock_analysis_project.stock_metrics"} */
create or replace   view USER_DB_BEETLE.analytics.stock_metrics
  
   as (
    -- models/stock_metrics.sql
with raw_data as (
  select *, row_number() over (partition by symbol order by date) as row_num
  from USER_DB_BEETLE.analytics.raw_stock_data
),

calc as (
  select 
    symbol,
    date,
    close,
    avg(close) over (partition by symbol order by date rows between 13 preceding and current row) as ma14,
    avg(close) over (partition by symbol order by date rows between 49 preceding and current row) as ma50
  from raw_data
)

select * from calc
  );
[0m19:50:20.391309 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.263 seconds
[0m19:50:20.393850 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eaba47b7-d82b-4001-a68a-2d31e8d48f28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff822b1970>]}
[0m19:50:20.394520 [info ] [Thread-1 (]: 4 of 4 OK created sql view model analytics.stock_metrics ....................... [[32mSUCCESS 1[0m in 0.27s]
[0m19:50:20.395301 [debug] [Thread-1 (]: Finished running node model.stock_analysis_project.stock_metrics
[0m19:50:20.396723 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:50:20.397090 [debug] [MainThread]: Connection 'model.stock_analysis_project.stock_metrics' was left open.
[0m19:50:20.397435 [debug] [MainThread]: On model.stock_analysis_project.stock_metrics: Close
[0m19:50:20.479056 [info ] [MainThread]: 
[0m19:50:20.479998 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 1.88 seconds (1.88s).
[0m19:50:20.481472 [debug] [MainThread]: Command end result
[0m19:50:20.512649 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:50:20.514874 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:50:20.521589 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m19:50:20.521949 [info ] [MainThread]: 
[0m19:50:20.522725 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:50:20.523049 [info ] [MainThread]: 
[0m19:50:20.523577 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m19:50:20.525859 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.1846468, "process_in_blocks": "0", "process_kernel_time": 0.246395, "process_mem_max_rss": "217792", "process_out_blocks": "2004", "process_user_time": 4.059459}
[0m19:50:20.526664 [debug] [MainThread]: Command `dbt run` succeeded at 19:50:20.526551 after 3.19 seconds
[0m19:50:20.527128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3bdf680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa83f6a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa3dd9ac0>]}
[0m19:50:20.527547 [debug] [MainThread]: Flushing usage events
[0m19:50:20.895173 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:50:24.266162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85761fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85763c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85763bf0>]}


============================== 19:50:24.272295 | 919389e4-100a-4f28-8ed9-30d82c2e76a6 ==============================
[0m19:50:24.272295 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:50:24.273120 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:50:25.046030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '919389e4-100a-4f28-8ed9-30d82c2e76a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff87449760>]}
[0m19:50:25.113047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '919389e4-100a-4f28-8ed9-30d82c2e76a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6c12a990>]}
[0m19:50:25.114506 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:50:25.225462 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:50:25.368411 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:50:25.368994 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:50:25.374519 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m19:50:25.420823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '919389e4-100a-4f28-8ed9-30d82c2e76a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff685d72c0>]}
[0m19:50:25.525151 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:50:25.529268 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:50:25.569391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '919389e4-100a-4f28-8ed9-30d82c2e76a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff68128e30>]}
[0m19:50:25.570100 [info ] [MainThread]: Found 4 models, 1 snapshot, 2 data tests, 474 macros
[0m19:50:25.570823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '919389e4-100a-4f28-8ed9-30d82c2e76a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff68647a70>]}
[0m19:50:25.572624 [info ] [MainThread]: 
[0m19:50:25.573209 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:50:25.573780 [info ] [MainThread]: 
[0m19:50:25.574588 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:50:25.580147 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE_snapshots'
[0m19:50:25.625562 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_snapshots"
[0m19:50:25.626378 [debug] [ThreadPool]: On list_USER_DB_BEETLE_snapshots: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_snapshots"} */
show objects in USER_DB_BEETLE.snapshots limit 10000;
[0m19:50:25.626721 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:50:25.977974 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.351 seconds
[0m19:50:25.980193 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_snapshots, now list_USER_DB_BEETLE_analytics)
[0m19:50:25.982848 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m19:50:25.983234 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m19:50:26.091645 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.108 seconds
[0m19:50:26.098562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '919389e4-100a-4f28-8ed9-30d82c2e76a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff680fc5c0>]}
[0m19:50:26.103601 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:50:26.104078 [info ] [Thread-1 (]: 1 of 2 START test not_null_stock_metrics_close ................................. [RUN]
[0m19:50:26.105298 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c)
[0m19:50:26.105705 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:50:26.122114 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:50:26.123693 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:50:26.163632 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:50:26.165203 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"
[0m19:50:26.165606 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select close
from USER_DB_BEETLE.analytics.stock_metrics
where close is null



      
    ) dbt_internal_test
[0m19:50:26.308728 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.143 seconds
[0m19:50:26.317808 [info ] [Thread-1 (]: 1 of 2 PASS not_null_stock_metrics_close ....................................... [[32mPASS[0m in 0.21s]
[0m19:50:26.318810 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c
[0m19:50:26.319293 [debug] [Thread-1 (]: Began running node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:50:26.319780 [info ] [Thread-1 (]: 2 of 2 START test not_null_stock_metrics_symbol ................................ [RUN]
[0m19:50:26.320409 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.stock_analysis_project.not_null_stock_metrics_close.ede30dfb3c, now test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7)
[0m19:50:26.320728 [debug] [Thread-1 (]: Began compiling node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:50:26.324536 [debug] [Thread-1 (]: Writing injected SQL for node "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:50:26.325633 [debug] [Thread-1 (]: Began executing node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:50:26.327760 [debug] [Thread-1 (]: Writing runtime sql for node "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:50:26.328974 [debug] [Thread-1 (]: Using snowflake connection "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"
[0m19:50:26.329350 [debug] [Thread-1 (]: On test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from USER_DB_BEETLE.analytics.stock_metrics
where symbol is null



      
    ) dbt_internal_test
[0m19:50:26.457737 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.128 seconds
[0m19:50:26.461681 [info ] [Thread-1 (]: 2 of 2 PASS not_null_stock_metrics_symbol ...................................... [[32mPASS[0m in 0.14s]
[0m19:50:26.463414 [debug] [Thread-1 (]: Finished running node test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7
[0m19:50:26.466371 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:50:26.467306 [debug] [MainThread]: Connection 'test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7' was left open.
[0m19:50:26.468192 [debug] [MainThread]: On test.stock_analysis_project.not_null_stock_metrics_symbol.991b6d7cf7: Close
[0m19:50:26.599647 [info ] [MainThread]: 
[0m19:50:26.606411 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 1.03 seconds (1.03s).
[0m19:50:26.625133 [debug] [MainThread]: Command end result
[0m19:50:26.672968 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:50:26.676537 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:50:26.694024 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m19:50:26.694647 [info ] [MainThread]: 
[0m19:50:26.696653 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:50:26.698015 [info ] [MainThread]: 
[0m19:50:26.699541 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m19:50:26.702886 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.481739, "process_in_blocks": "0", "process_kernel_time": 0.35731, "process_mem_max_rss": "219992", "process_out_blocks": "1980", "process_user_time": 4.675489}
[0m19:50:26.705029 [debug] [MainThread]: Command `dbt test` succeeded at 19:50:26.704475 after 2.48 seconds
[0m19:50:26.706941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff852bcaa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85378740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff68663080>]}
[0m19:50:26.708250 [debug] [MainThread]: Flushing usage events
[0m19:50:27.026217 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:50:29.983913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa766da60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa7808c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa766fa40>]}


============================== 19:50:29.991013 | a9b34604-a5f6-4c10-9b18-bdb03aa9d5d3 ==============================
[0m19:50:29.991013 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:50:29.991930 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dags/stock_analysis_project/config', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dags/stock_analysis_project/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt snapshot --profiles-dir /opt/airflow/dags/stock_analysis_project/config', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:50:30.772296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a9b34604-a5f6-4c10-9b18-bdb03aa9d5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa70f34d0>]}
[0m19:50:30.820270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a9b34604-a5f6-4c10-9b18-bdb03aa9d5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86d8bfb0>]}
[0m19:50:30.821065 [info ] [MainThread]: Registered adapter: snowflake=1.9.2
[0m19:50:30.934533 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:50:31.083790 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:50:31.084342 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:50:31.089728 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.stock_analysis_project.stock_data
[0m19:50:31.132644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a9b34604-a5f6-4c10-9b18-bdb03aa9d5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86c71a60>]}
[0m19:50:31.223653 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:50:31.225694 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:50:31.245871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a9b34604-a5f6-4c10-9b18-bdb03aa9d5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86a4deb0>]}
[0m19:50:31.246442 [info ] [MainThread]: Found 4 models, 1 snapshot, 2 data tests, 474 macros
[0m19:50:31.247156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9b34604-a5f6-4c10-9b18-bdb03aa9d5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86784680>]}
[0m19:50:31.249177 [info ] [MainThread]: 
[0m19:50:31.249807 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:50:31.250295 [info ] [MainThread]: 
[0m19:50:31.251259 [debug] [MainThread]: Acquiring new snowflake connection 'master'
[0m19:50:31.252585 [debug] [ThreadPool]: Acquiring new snowflake connection 'list_USER_DB_BEETLE'
[0m19:50:31.286743 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE"
[0m19:50:31.287286 [debug] [ThreadPool]: On list_USER_DB_BEETLE: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE"} */
show terse schemas in database USER_DB_BEETLE
    limit 10000
[0m19:50:31.287628 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:50:31.693797 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 0.406 seconds
[0m19:50:31.700280 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE, now list_USER_DB_BEETLE_snapshots)
[0m19:50:31.710241 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_snapshots"
[0m19:50:31.710670 [debug] [ThreadPool]: On list_USER_DB_BEETLE_snapshots: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_snapshots"} */
show objects in USER_DB_BEETLE.snapshots limit 10000;
[0m19:50:31.813050 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 0.102 seconds
[0m19:50:31.816507 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_snapshots, now list_USER_DB_BEETLE_analytics)
[0m19:50:31.819315 [debug] [ThreadPool]: Using snowflake connection "list_USER_DB_BEETLE_analytics"
[0m19:50:31.819799 [debug] [ThreadPool]: On list_USER_DB_BEETLE_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "connection_name": "list_USER_DB_BEETLE_analytics"} */
show objects in USER_DB_BEETLE.analytics limit 10000;
[0m19:50:31.933116 [debug] [ThreadPool]: SQL status: SUCCESS 10 in 0.113 seconds
[0m19:50:31.938486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a9b34604-a5f6-4c10-9b18-bdb03aa9d5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85be3860>]}
[0m19:50:31.942897 [debug] [Thread-1 (]: Began running node snapshot.stock_analysis_project.stock_snapshot
[0m19:50:31.943570 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.stock_snapshot ................................. [RUN]
[0m19:50:31.944479 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_USER_DB_BEETLE_analytics, now snapshot.stock_analysis_project.stock_snapshot)
[0m19:50:31.944912 [debug] [Thread-1 (]: Began compiling node snapshot.stock_analysis_project.stock_snapshot
[0m19:50:31.952709 [debug] [Thread-1 (]: Began executing node snapshot.stock_analysis_project.stock_snapshot
[0m19:50:32.014551 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:32.015161 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
select * from (
        select close from (
                


select * from USER_DB_BEETLE.analytics.raw_stock_data

            ) subq
    ) as __dbt_sbq
    where false
    limit 0
[0m19:50:32.108542 [debug] [Thread-1 (]: SQL status: SUCCESS 0 in 0.093 seconds
[0m19:50:32.117465 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:32.118210 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
describe table "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT"
[0m19:50:32.210115 [debug] [Thread-1 (]: SQL status: SUCCESS 11 in 0.091 seconds
[0m19:50:32.218665 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:32.219267 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
describe table "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT"
[0m19:50:32.291311 [debug] [Thread-1 (]: SQL status: SUCCESS 11 in 0.071 seconds
[0m19:50:32.344873 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:32.345494 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
create or replace temporary table "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT__dbt_tmp"
         as
        (
    
    with snapshot_query as (

        


select * from USER_DB_BEETLE.analytics.raw_stock_data


    ),

    snapshotted_data as (

        select *, 
    
        symbol || date as dbt_unique_key
    

        from "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT"
        where
            
                dbt_valid_to is null
            

    ),

    insertions_source_data as (

        select *, 
    
        symbol || date as dbt_unique_key
    
,
            to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_updated_at,
            to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_valid_from,
            
  
  coalesce(nullif(to_timestamp_ntz(convert_timezone('UTC', current_timestamp())), to_timestamp_ntz(convert_timezone('UTC', current_timestamp()))), null)
  as dbt_valid_to
,
            md5(coalesce(cast(symbol || date as varchar ), '')
         || '|' || coalesce(cast(to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        symbol || date as dbt_unique_key
    
,
            to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_updated_at,
            to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_valid_from,
            to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and ((snapshotted_data."CLOSE" != source_data."CLOSE"
        or
        (
            ((snapshotted_data."CLOSE" is null) and not (source_data."CLOSE" is null))
            or
            ((not snapshotted_data."CLOSE" is null) and (source_data."CLOSE" is null))
        )))

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data."CLOSE" != source_data."CLOSE"
        or
        (
            ((snapshotted_data."CLOSE" is null) and not (source_data."CLOSE" is null))
            or
            ((not snapshotted_data."CLOSE" is null) and (source_data."CLOSE" is null))
        ))
        )
    )

    select * from insertions
    union all
    select * from updates

        );
[0m19:50:33.019060 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.673 seconds
[0m19:50:33.025507 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:33.026862 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
describe table "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT__dbt_tmp"
[0m19:50:33.096874 [debug] [Thread-1 (]: SQL status: SUCCESS 13 in 0.069 seconds
[0m19:50:33.104480 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:33.105619 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
describe table "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT"
[0m19:50:33.186233 [debug] [Thread-1 (]: SQL status: SUCCESS 11 in 0.080 seconds
[0m19:50:33.190051 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:33.190637 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
describe table "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT__dbt_tmp"
[0m19:50:33.262658 [debug] [Thread-1 (]: SQL status: SUCCESS 13 in 0.071 seconds
[0m19:50:33.267221 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:33.267929 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
describe table "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT"
[0m19:50:33.322964 [debug] [Thread-1 (]: SQL status: SUCCESS 11 in 0.054 seconds
[0m19:50:33.331485 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:33.332036 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
describe table "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT__dbt_tmp"
[0m19:50:33.402909 [debug] [Thread-1 (]: SQL status: SUCCESS 13 in 0.070 seconds
[0m19:50:33.424531 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:33.425374 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
/* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
select * from (
        
    
    with snapshot_query as (

        


select * from USER_DB_BEETLE.analytics.raw_stock_data


    ),

    snapshotted_data as (

        select *, 
    
        symbol || date as dbt_unique_key
    

        from "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT"
        where
            
                dbt_valid_to is null
            

    ),

    insertions_source_data as (

        select *, 
    
        symbol || date as dbt_unique_key
    
,
            to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_updated_at,
            to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_valid_from,
            
  
  coalesce(nullif(to_timestamp_ntz(convert_timezone('UTC', current_timestamp())), to_timestamp_ntz(convert_timezone('UTC', current_timestamp()))), null)
  as dbt_valid_to
,
            md5(coalesce(cast(symbol || date as varchar ), '')
         || '|' || coalesce(cast(to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        symbol || date as dbt_unique_key
    
,
            to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_updated_at,
            to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_valid_from,
            to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and ((snapshotted_data."CLOSE" != source_data."CLOSE"
        or
        (
            ((snapshotted_data."CLOSE" is null) and not (source_data."CLOSE" is null))
            or
            ((not snapshotted_data."CLOSE" is null) and (source_data."CLOSE" is null))
        )))

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data."CLOSE" != source_data."CLOSE"
        or
        (
            ((snapshotted_data."CLOSE" is null) and not (source_data."CLOSE" is null))
            or
            ((not snapshotted_data."CLOSE" is null) and (source_data."CLOSE" is null))
        ))
        )
    )

    select * from insertions
    union all
    select * from updates

    ) as __dbt_sbq
    where false
    limit 0
[0m19:50:33.742231 [debug] [Thread-1 (]: SQL status: SUCCESS 0 in 0.315 seconds
[0m19:50:33.757880 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:33.762450 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
/* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
select * from (
        select to_timestamp_ntz(convert_timezone('UTC', current_timestamp())) as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0
[0m19:50:33.817461 [debug] [Thread-1 (]: SQL status: SUCCESS 0 in 0.054 seconds
[0m19:50:33.818283 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:33.820167 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:33.820505 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
BEGIN
[0m19:50:33.922810 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.102 seconds
[0m19:50:33.923526 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:33.923992 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
merge into "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT" as DBT_INTERNAL_DEST
    using "USER_DB_BEETLE"."SNAPSHOTS"."STOCK_SNAPSHOT__dbt_tmp" as DBT_INTERNAL_SOURCE
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id

    when matched
     
       and DBT_INTERNAL_DEST.dbt_valid_to is null
     
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert ("SYMBOL", "DATE", "OPEN", "HIGH", "LOW", "CLOSE", "VOLUME", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")
        values ("SYMBOL", "DATE", "OPEN", "HIGH", "LOW", "CLOSE", "VOLUME", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")

;
[0m19:50:34.365695 [debug] [Thread-1 (]: SQL status: SUCCESS 0 in 0.441 seconds
[0m19:50:34.366346 [debug] [Thread-1 (]: Using snowflake connection "snapshot.stock_analysis_project.stock_snapshot"
[0m19:50:34.366770 [debug] [Thread-1 (]: On snapshot.stock_analysis_project.stock_snapshot: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "stock_analysis_project", "target_name": "dev", "node_id": "snapshot.stock_analysis_project.stock_snapshot"} */
COMMIT
[0m19:50:34.679989 [debug] [Thread-1 (]: SQL status: SUCCESS 1 in 0.313 seconds
[0m19:50:34.707566 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a9b34604-a5f6-4c10-9b18-bdb03aa9d5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9a8f080>]}
[0m19:50:34.708796 [info ] [Thread-1 (]: 1 of 1 OK snapshotted snapshots.stock_snapshot ................................. [[32mSUCCESS 0[0m in 2.76s]
[0m19:50:34.709780 [debug] [Thread-1 (]: Finished running node snapshot.stock_analysis_project.stock_snapshot
[0m19:50:34.711345 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:50:34.711683 [debug] [MainThread]: Connection 'snapshot.stock_analysis_project.stock_snapshot' was left open.
[0m19:50:34.711988 [debug] [MainThread]: On snapshot.stock_analysis_project.stock_snapshot: Close
[0m19:50:34.795612 [info ] [MainThread]: 
[0m19:50:34.796473 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 3.54 seconds (3.54s).
[0m19:50:34.797309 [debug] [MainThread]: Command end result
[0m19:50:34.828923 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dags/stock_analysis_project/target/manifest.json
[0m19:50:34.831674 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dags/stock_analysis_project/target/semantic_manifest.json
[0m19:50:34.839707 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dags/stock_analysis_project/target/run_results.json
[0m19:50:34.840500 [info ] [MainThread]: 
[0m19:50:34.841356 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:50:34.841851 [info ] [MainThread]: 
[0m19:50:34.842399 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:50:34.843502 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 4.906142, "process_in_blocks": "0", "process_kernel_time": 0.285798, "process_mem_max_rss": "219020", "process_out_blocks": "2000", "process_user_time": 4.452443}
[0m19:50:34.843975 [debug] [MainThread]: Command `dbt snapshot` succeeded at 19:50:34.843863 after 4.91 seconds
[0m19:50:34.844347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa7f07c20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9d8acf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85be37a0>]}
[0m19:50:34.844736 [debug] [MainThread]: Flushing usage events
[0m19:50:35.158120 [debug] [MainThread]: An error was encountered while trying to flush usage events
